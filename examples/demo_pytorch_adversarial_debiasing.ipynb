{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/arezzy17/AIF360/blob/master/examples/demo_pytorch_adversarial_debiasing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "05jtdvK4OUVZ"
   },
   "source": [
    "#### This notebook demonstrates the use of adversarial debiasing algorithm to learn a fair classifier.\n",
    "Adversarial debiasing [1] is an in-processing technique that learns a classifier to maximize prediction accuracy and simultaneously reduce an adversary's ability to determine the protected attribute from the predictions. This approach leads to a fair classifier as the predictions cannot carry any group discrimination information that the adversary can exploit. We will see how to use this algorithm for learning models with and without fairness constraints and apply them on the Adult dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5rccV9sUOUVc",
    "outputId": "a536dc16-15bc-40a2-b445-b7dc183a9bef"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:No module named 'tensorflow': AdversarialDebiasing will be unavailable. To install, run:\n",
      "pip install 'aif360[AdversarialDebiasing]'\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "# Load all necessary packages\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "from aif360.datasets import BinaryLabelDataset\n",
    "from aif360.datasets import AdultDataset, GermanDataset, CompasDataset\n",
    "from aif360.metrics import BinaryLabelDatasetMetric\n",
    "from aif360.metrics import ClassificationMetric\n",
    "from aif360.metrics.utils import compute_boolean_conditioning_vector\n",
    "\n",
    "from aif360.algorithms.preprocessing.optim_preproc_helpers.data_preproc_functions import load_preproc_data_adult, load_preproc_data_compas, load_preproc_data_german\n",
    "\n",
    "from aif360.pytorch.inprocessing.adversarial_debiasing import AdversarialDebiasing, ClassifierModel, AdversaryModel, default_classifier_ann, StaircaseExponentialLR\n",
    "from aif360.algorithms import Transformer\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler, MaxAbsScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from IPython.display import Markdown, display\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jVWm54jkOUVm"
   },
   "source": [
    "#### Load dataset and set options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "b3VphoFfOUVm"
   },
   "outputs": [],
   "source": [
    "# Get the dataset and split into train and test\n",
    "dataset_orig = load_preproc_data_adult()\n",
    "\n",
    "privileged_groups = [{'sex': 1}]\n",
    "unprivileged_groups = [{'sex': 0}]\n",
    "\n",
    "dataset_orig_train, dataset_orig_test = dataset_orig.split([0.7], shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34189, 18)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_orig_train.features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "b0Fs80vmOUVy",
    "outputId": "60b77184-86e2-44a6-a82c-effb393eb188"
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Training Dataset shape"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(34189, 18)\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Favorable and unfavorable labels"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 0.0\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Protected attribute names"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sex', 'race']\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Privileged and unprivileged protected attribute values"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([1.]), array([1.])] [array([0.]), array([0.])]\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Dataset feature names"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['race', 'sex', 'Age (decade)=10', 'Age (decade)=20', 'Age (decade)=30', 'Age (decade)=40', 'Age (decade)=50', 'Age (decade)=60', 'Age (decade)=>=70', 'Education Years=6', 'Education Years=7', 'Education Years=8', 'Education Years=9', 'Education Years=10', 'Education Years=11', 'Education Years=12', 'Education Years=<6', 'Education Years=>12']\n"
     ]
    }
   ],
   "source": [
    "# print out some labels, names, etc.\n",
    "display(Markdown(\"#### Training Dataset shape\"))\n",
    "print(dataset_orig_train.features.shape)\n",
    "display(Markdown(\"#### Favorable and unfavorable labels\"))\n",
    "print(dataset_orig_train.favorable_label, dataset_orig_train.unfavorable_label)\n",
    "display(Markdown(\"#### Protected attribute names\"))\n",
    "print(dataset_orig_train.protected_attribute_names)\n",
    "display(Markdown(\"#### Privileged and unprivileged protected attribute values\"))\n",
    "print(dataset_orig_train.privileged_protected_attributes, \n",
    "      dataset_orig_train.unprivileged_protected_attributes)\n",
    "display(Markdown(\"#### Dataset feature names\"))\n",
    "print(dataset_orig_train.feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3hvQSijEOUV3"
   },
   "source": [
    "#### Metric for original training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gF4S2ecCOUV3",
    "outputId": "037dae18-f133-4a07-ba13-b133c3e8fba9"
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Original training dataset"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: Difference in mean outcomes between unprivileged and privileged groups = -0.194600\n",
      "Test set: Difference in mean outcomes between unprivileged and privileged groups = -0.194408\n"
     ]
    }
   ],
   "source": [
    "# Metric for the original dataset\n",
    "metric_orig_train = BinaryLabelDatasetMetric(dataset_orig_train, \n",
    "                                             unprivileged_groups=unprivileged_groups,\n",
    "                                             privileged_groups=privileged_groups)\n",
    "display(Markdown(\"#### Original training dataset\"))\n",
    "print(\"Train set: Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_orig_train.mean_difference())\n",
    "metric_orig_test = BinaryLabelDatasetMetric(dataset_orig_test, \n",
    "                                             unprivileged_groups=unprivileged_groups,\n",
    "                                             privileged_groups=privileged_groups)\n",
    "print(\"Test set: Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_orig_test.mean_difference())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1h7o7U_UOUV9",
    "outputId": "6b99f507-dfe1-42b3-cdd3-b995d7c5a758"
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Scaled dataset - Verify that the scaling does not affect the group label statistics"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: Difference in mean outcomes between unprivileged and privileged groups = -0.194600\n",
      "Test set: Difference in mean outcomes between unprivileged and privileged groups = -0.194408\n"
     ]
    }
   ],
   "source": [
    "min_max_scaler = MaxAbsScaler()\n",
    "dataset_orig_train.features = min_max_scaler.fit_transform(dataset_orig_train.features)\n",
    "dataset_orig_test.features = min_max_scaler.transform(dataset_orig_test.features)\n",
    "metric_scaled_train = BinaryLabelDatasetMetric(dataset_orig_train, \n",
    "                             unprivileged_groups=unprivileged_groups,\n",
    "                             privileged_groups=privileged_groups)\n",
    "display(Markdown(\"#### Scaled dataset - Verify that the scaling does not affect the group label statistics\"))\n",
    "print(\"Train set: Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_scaled_train.mean_difference())\n",
    "metric_scaled_test = BinaryLabelDatasetMetric(dataset_orig_test, \n",
    "                             unprivileged_groups=unprivileged_groups,\n",
    "                             privileged_groups=privileged_groups)\n",
    "print(\"Test set: Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_scaled_test.mean_difference())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "k-ISMfC3OUWB"
   },
   "source": [
    "### Learn plan classifier without debiasing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load post-processing algorithm that equalizes the odds\n",
    "# Learn parameters with debias set to False\n",
    "plain_model = AdversarialDebiasing(privileged_groups = privileged_groups,\n",
    "                                   unprivileged_groups = unprivileged_groups,\n",
    "                                   input_size = 18, debias = False,\n",
    "                                   verbose = True, seed = 360)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to train model(s) on cpu:\n",
      "Learning rate of the classifier model is now set to 0.001\n",
      "Epoch: [1/50] Batch: [1/268]\tClassifier Loss: 0.7081\tC(x): 0.7081\n",
      "Epoch: [1/50] Batch: [201/268]\tClassifier Loss: 0.4068\tC(x): 0.4893\n",
      "Epoch: [2/50] Batch: [1/268]\tClassifier Loss: 0.4824\tC(x): 0.4764\n",
      "Epoch: [2/50] Batch: [201/268]\tClassifier Loss: 0.3790\tC(x): 0.4557\n",
      "Epoch: [3/50] Batch: [1/268]\tClassifier Loss: 0.4047\tC(x): 0.4518\n",
      "Epoch: [3/50] Batch: [201/268]\tClassifier Loss: 0.4590\tC(x): 0.4448\n",
      "Epoch: [4/50] Batch: [1/268]\tClassifier Loss: 0.3586\tC(x): 0.4433\n",
      "Learning rate of the classifier model is now set to 0.00096\n",
      "Epoch: [4/50] Batch: [201/268]\tClassifier Loss: 0.4351\tC(x): 0.4396\n",
      "Epoch: [5/50] Batch: [1/268]\tClassifier Loss: 0.4298\tC(x): 0.4387\n",
      "Epoch: [5/50] Batch: [201/268]\tClassifier Loss: 0.3938\tC(x): 0.4364\n",
      "Epoch: [6/50] Batch: [1/268]\tClassifier Loss: 0.3386\tC(x): 0.4357\n",
      "Epoch: [6/50] Batch: [201/268]\tClassifier Loss: 0.4331\tC(x): 0.4343\n",
      "Epoch: [7/50] Batch: [1/268]\tClassifier Loss: 0.5622\tC(x): 0.4338\n",
      "Epoch: [7/50] Batch: [201/268]\tClassifier Loss: 0.4152\tC(x): 0.4330\n",
      "Epoch: [8/50] Batch: [1/268]\tClassifier Loss: 0.4992\tC(x): 0.4324\n",
      "Learning rate of the classifier model is now set to 0.0009216\n",
      "Epoch: [8/50] Batch: [201/268]\tClassifier Loss: 0.4612\tC(x): 0.4314\n",
      "Epoch: [9/50] Batch: [1/268]\tClassifier Loss: 0.3674\tC(x): 0.4313\n",
      "Epoch: [9/50] Batch: [201/268]\tClassifier Loss: 0.4174\tC(x): 0.4307\n",
      "Epoch: [10/50] Batch: [1/268]\tClassifier Loss: 0.4325\tC(x): 0.4305\n",
      "Epoch: [10/50] Batch: [201/268]\tClassifier Loss: 0.3917\tC(x): 0.4302\n",
      "Epoch: [11/50] Batch: [1/268]\tClassifier Loss: 0.4058\tC(x): 0.4297\n",
      "Epoch: [11/50] Batch: [201/268]\tClassifier Loss: 0.4504\tC(x): 0.4293\n",
      "Epoch: [12/50] Batch: [1/268]\tClassifier Loss: 0.4164\tC(x): 0.4291\n",
      "Learning rate of the classifier model is now set to 0.0008847359999999999\n",
      "Epoch: [12/50] Batch: [201/268]\tClassifier Loss: 0.4300\tC(x): 0.4287\n",
      "Epoch: [13/50] Batch: [1/268]\tClassifier Loss: 0.4520\tC(x): 0.4288\n",
      "Epoch: [13/50] Batch: [201/268]\tClassifier Loss: 0.4482\tC(x): 0.4284\n",
      "Epoch: [14/50] Batch: [1/268]\tClassifier Loss: 0.3643\tC(x): 0.4283\n",
      "Epoch: [14/50] Batch: [201/268]\tClassifier Loss: 0.4103\tC(x): 0.4278\n",
      "Epoch: [15/50] Batch: [1/268]\tClassifier Loss: 0.3940\tC(x): 0.4278\n",
      "Epoch: [15/50] Batch: [201/268]\tClassifier Loss: 0.4211\tC(x): 0.4275\n",
      "Learning rate of the classifier model is now set to 0.0008493465599999999\n",
      "Epoch: [16/50] Batch: [1/268]\tClassifier Loss: 0.4536\tC(x): 0.4275\n",
      "Epoch: [16/50] Batch: [201/268]\tClassifier Loss: 0.3636\tC(x): 0.4273\n",
      "Epoch: [17/50] Batch: [1/268]\tClassifier Loss: 0.4643\tC(x): 0.4272\n",
      "Epoch: [17/50] Batch: [201/268]\tClassifier Loss: 0.4540\tC(x): 0.4270\n",
      "Epoch: [18/50] Batch: [1/268]\tClassifier Loss: 0.4427\tC(x): 0.4269\n",
      "Epoch: [18/50] Batch: [201/268]\tClassifier Loss: 0.4233\tC(x): 0.4267\n",
      "Epoch: [19/50] Batch: [1/268]\tClassifier Loss: 0.3550\tC(x): 0.4267\n",
      "Learning rate of the classifier model is now set to 0.0008153726975999999\n",
      "Epoch: [19/50] Batch: [201/268]\tClassifier Loss: 0.5513\tC(x): 0.4265\n",
      "Epoch: [20/50] Batch: [1/268]\tClassifier Loss: 0.3707\tC(x): 0.4265\n",
      "Epoch: [20/50] Batch: [201/268]\tClassifier Loss: 0.4434\tC(x): 0.4264\n",
      "Epoch: [21/50] Batch: [1/268]\tClassifier Loss: 0.3663\tC(x): 0.4263\n",
      "Epoch: [21/50] Batch: [201/268]\tClassifier Loss: 0.3833\tC(x): 0.4261\n",
      "Epoch: [22/50] Batch: [1/268]\tClassifier Loss: 0.3934\tC(x): 0.4260\n",
      "Epoch: [22/50] Batch: [201/268]\tClassifier Loss: 0.4681\tC(x): 0.4259\n",
      "Epoch: [23/50] Batch: [1/268]\tClassifier Loss: 0.3974\tC(x): 0.4259\n",
      "Learning rate of the classifier model is now set to 0.0007827577896959999\n",
      "Epoch: [23/50] Batch: [201/268]\tClassifier Loss: 0.4044\tC(x): 0.4257\n",
      "Epoch: [24/50] Batch: [1/268]\tClassifier Loss: 0.4182\tC(x): 0.4257\n",
      "Epoch: [24/50] Batch: [201/268]\tClassifier Loss: 0.4230\tC(x): 0.4256\n",
      "Epoch: [25/50] Batch: [1/268]\tClassifier Loss: 0.3820\tC(x): 0.4255\n",
      "Epoch: [25/50] Batch: [201/268]\tClassifier Loss: 0.4436\tC(x): 0.4254\n",
      "Epoch: [26/50] Batch: [1/268]\tClassifier Loss: 0.4070\tC(x): 0.4254\n",
      "Epoch: [26/50] Batch: [201/268]\tClassifier Loss: 0.4168\tC(x): 0.4253\n",
      "Epoch: [27/50] Batch: [1/268]\tClassifier Loss: 0.3843\tC(x): 0.4252\n",
      "Learning rate of the classifier model is now set to 0.0007514474781081599\n",
      "Epoch: [27/50] Batch: [201/268]\tClassifier Loss: 0.4178\tC(x): 0.4251\n",
      "Epoch: [28/50] Batch: [1/268]\tClassifier Loss: 0.4175\tC(x): 0.4250\n",
      "Epoch: [28/50] Batch: [201/268]\tClassifier Loss: 0.3722\tC(x): 0.4250\n",
      "Epoch: [29/50] Batch: [1/268]\tClassifier Loss: 0.3644\tC(x): 0.4249\n",
      "Epoch: [29/50] Batch: [201/268]\tClassifier Loss: 0.3903\tC(x): 0.4248\n",
      "Epoch: [30/50] Batch: [1/268]\tClassifier Loss: 0.3835\tC(x): 0.4248\n",
      "Epoch: [30/50] Batch: [201/268]\tClassifier Loss: 0.3945\tC(x): 0.4247\n",
      "Learning rate of the classifier model is now set to 0.0007213895789838334\n",
      "Epoch: [31/50] Batch: [1/268]\tClassifier Loss: 0.4420\tC(x): 0.4247\n",
      "Epoch: [31/50] Batch: [201/268]\tClassifier Loss: 0.3988\tC(x): 0.4246\n",
      "Epoch: [32/50] Batch: [1/268]\tClassifier Loss: 0.4217\tC(x): 0.4246\n",
      "Epoch: [32/50] Batch: [201/268]\tClassifier Loss: 0.4609\tC(x): 0.4245\n",
      "Epoch: [33/50] Batch: [1/268]\tClassifier Loss: 0.4514\tC(x): 0.4245\n",
      "Epoch: [33/50] Batch: [201/268]\tClassifier Loss: 0.4148\tC(x): 0.4244\n",
      "Epoch: [34/50] Batch: [1/268]\tClassifier Loss: 0.4192\tC(x): 0.4244\n",
      "Learning rate of the classifier model is now set to 0.0006925339958244801\n",
      "Epoch: [34/50] Batch: [201/268]\tClassifier Loss: 0.3914\tC(x): 0.4243\n",
      "Epoch: [35/50] Batch: [1/268]\tClassifier Loss: 0.5014\tC(x): 0.4243\n",
      "Epoch: [35/50] Batch: [201/268]\tClassifier Loss: 0.5042\tC(x): 0.4243\n",
      "Epoch: [36/50] Batch: [1/268]\tClassifier Loss: 0.3809\tC(x): 0.4242\n",
      "Epoch: [36/50] Batch: [201/268]\tClassifier Loss: 0.4075\tC(x): 0.4242\n",
      "Epoch: [37/50] Batch: [1/268]\tClassifier Loss: 0.5091\tC(x): 0.4241\n",
      "Epoch: [37/50] Batch: [201/268]\tClassifier Loss: 0.4753\tC(x): 0.4241\n",
      "Epoch: [38/50] Batch: [1/268]\tClassifier Loss: 0.4361\tC(x): 0.4241\n",
      "Learning rate of the classifier model is now set to 0.0006648326359915007\n",
      "Epoch: [38/50] Batch: [201/268]\tClassifier Loss: 0.4139\tC(x): 0.4240\n",
      "Epoch: [39/50] Batch: [1/268]\tClassifier Loss: 0.4223\tC(x): 0.4240\n",
      "Epoch: [39/50] Batch: [201/268]\tClassifier Loss: 0.3558\tC(x): 0.4239\n",
      "Epoch: [40/50] Batch: [1/268]\tClassifier Loss: 0.4198\tC(x): 0.4239\n",
      "Epoch: [40/50] Batch: [201/268]\tClassifier Loss: 0.4431\tC(x): 0.4239\n",
      "Epoch: [41/50] Batch: [1/268]\tClassifier Loss: 0.4590\tC(x): 0.4239\n",
      "Epoch: [41/50] Batch: [201/268]\tClassifier Loss: 0.4232\tC(x): 0.4238\n",
      "Epoch: [42/50] Batch: [1/268]\tClassifier Loss: 0.4773\tC(x): 0.4238\n",
      "Learning rate of the classifier model is now set to 0.0006382393305518408\n",
      "Epoch: [42/50] Batch: [201/268]\tClassifier Loss: 0.4543\tC(x): 0.4237\n",
      "Epoch: [43/50] Batch: [1/268]\tClassifier Loss: 0.4359\tC(x): 0.4237\n",
      "Epoch: [43/50] Batch: [201/268]\tClassifier Loss: 0.3718\tC(x): 0.4236\n",
      "Epoch: [44/50] Batch: [1/268]\tClassifier Loss: 0.3493\tC(x): 0.4236\n",
      "Epoch: [44/50] Batch: [201/268]\tClassifier Loss: 0.4804\tC(x): 0.4236\n",
      "Epoch: [45/50] Batch: [1/268]\tClassifier Loss: 0.3822\tC(x): 0.4236\n",
      "Epoch: [45/50] Batch: [201/268]\tClassifier Loss: 0.4111\tC(x): 0.4235\n",
      "Learning rate of the classifier model is now set to 0.0006127097573297671\n",
      "Epoch: [46/50] Batch: [1/268]\tClassifier Loss: 0.4509\tC(x): 0.4235\n",
      "Epoch: [46/50] Batch: [201/268]\tClassifier Loss: 0.5174\tC(x): 0.4234\n",
      "Epoch: [47/50] Batch: [1/268]\tClassifier Loss: 0.3435\tC(x): 0.4234\n",
      "Epoch: [47/50] Batch: [201/268]\tClassifier Loss: 0.4208\tC(x): 0.4235\n",
      "Epoch: [48/50] Batch: [1/268]\tClassifier Loss: 0.3704\tC(x): 0.4234\n",
      "Epoch: [48/50] Batch: [201/268]\tClassifier Loss: 0.4627\tC(x): 0.4233\n",
      "Epoch: [49/50] Batch: [1/268]\tClassifier Loss: 0.4170\tC(x): 0.4233\n",
      "Learning rate of the classifier model is now set to 0.0005882013670365765\n",
      "Epoch: [49/50] Batch: [201/268]\tClassifier Loss: 0.4144\tC(x): 0.4233\n",
      "Epoch: [50/50] Batch: [1/268]\tClassifier Loss: 0.4251\tC(x): 0.4233\n",
      "Epoch: [50/50] Batch: [201/268]\tClassifier Loss: 0.4198\tC(x): 0.4232\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<aif360.pytorch.inprocessing.adversarial_debiasing.AdversarialDebiasing at 0x19169021048>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plain_model.fit(dataset_orig_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the plain model to test data\n",
    "dataset_nodebiasing_train = plain_model.predict(dataset_orig_train)\n",
    "dataset_nodebiasing_test = plain_model.predict(dataset_orig_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "U9Ij08GhOUWS",
    "outputId": "c62e42f8-4b79-485e-b5a5-41dd17b3edec"
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Plain model - without debiasing - dataset metrics"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: Difference in mean outcomes between unprivileged and privileged groups = -0.217658\n",
      "Test set: Difference in mean outcomes between unprivileged and privileged groups = -0.210708\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Plain model - without debiasing - classification metrics"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Classification accuracy = 0.805364\n",
      "Test set: Balanced classification accuracy = 0.661739\n",
      "Test set: Disparate impact = 0.000000\n",
      "Test set: Equal opportunity difference = -0.455312\n",
      "Test set: Average odds difference = -0.280433\n",
      "Test set: Theil_index = 0.176247\n"
     ]
    }
   ],
   "source": [
    "# Metrics for the dataset from plain model (without debiasing)\n",
    "display(Markdown(\"#### Plain model - without debiasing - dataset metrics\"))\n",
    "metric_dataset_nodebiasing_train = BinaryLabelDatasetMetric(dataset_nodebiasing_train, \n",
    "                                             unprivileged_groups=unprivileged_groups,\n",
    "                                             privileged_groups=privileged_groups)\n",
    "\n",
    "print(\"Train set: Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_dataset_nodebiasing_train.mean_difference())\n",
    "\n",
    "metric_dataset_nodebiasing_test = BinaryLabelDatasetMetric(dataset_nodebiasing_test, \n",
    "                                             unprivileged_groups=unprivileged_groups,\n",
    "                                             privileged_groups=privileged_groups)\n",
    "\n",
    "print(\"Test set: Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_dataset_nodebiasing_test.mean_difference())\n",
    "\n",
    "display(Markdown(\"#### Plain model - without debiasing - classification metrics\"))\n",
    "classified_metric_nodebiasing_test = ClassificationMetric(dataset_orig_test, \n",
    "                                                 dataset_nodebiasing_test,\n",
    "                                                 unprivileged_groups=unprivileged_groups,\n",
    "                                                 privileged_groups=privileged_groups)\n",
    "print(\"Test set: Classification accuracy = %f\" % classified_metric_nodebiasing_test.accuracy())\n",
    "TPR = classified_metric_nodebiasing_test.true_positive_rate()\n",
    "TNR = classified_metric_nodebiasing_test.true_negative_rate()\n",
    "bal_acc_nodebiasing_test = 0.5*(TPR+TNR)\n",
    "print(\"Test set: Balanced classification accuracy = %f\" % bal_acc_nodebiasing_test)\n",
    "print(\"Test set: Disparate impact = %f\" % classified_metric_nodebiasing_test.disparate_impact())\n",
    "print(\"Test set: Equal opportunity difference = %f\" % classified_metric_nodebiasing_test.equal_opportunity_difference())\n",
    "print(\"Test set: Average odds difference = %f\" % classified_metric_nodebiasing_test.average_odds_difference())\n",
    "print(\"Test set: Theil_index = %f\" % classified_metric_nodebiasing_test.theil_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lzvuFHvOOUWX"
   },
   "source": [
    "### Apply in-processing algorithm based on adversarial learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "N4D6YRyZOUWd"
   },
   "outputs": [],
   "source": [
    "# Learn parameters with debias set to True\n",
    "debiased_model = AdversarialDebiasing(privileged_groups = privileged_groups,\n",
    "                                      unprivileged_groups = unprivileged_groups,\n",
    "                                      input_size = 18, debias = True,\n",
    "                                      verbose = True, seed = 360)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "neS5Ouj5OUWn",
    "outputId": "1f9a5eb1-61a6-4f04-ed18-339007cd285b",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to train model(s) on cpu:\n",
      "Learning rate of the classifier model is now set to 0.001\n",
      "Learning rate of the adversary model is now set to 0.001\n",
      "Epoch: [1/50] Batch: [1/268]\tClassifier_Loss: 0.7081\tAdversary Loss: 0.6451\tC(x): 0.7081\tA(x, y): 0.6451\n",
      "Epoch: [1/50] Batch: [201/268]\tClassifier_Loss: 0.5838\tAdversary Loss: 0.6344\tC(x): 0.6126\tA(x, y): 0.6364\n",
      "Epoch: [2/50] Batch: [1/268]\tClassifier_Loss: 0.5878\tAdversary Loss: 0.6298\tC(x): 0.6073\tA(x, y): 0.6378\n",
      "Epoch: [2/50] Batch: [201/268]\tClassifier_Loss: 0.5292\tAdversary Loss: 0.6507\tC(x): 0.5893\tA(x, y): 0.6384\n",
      "Epoch: [3/50] Batch: [1/268]\tClassifier_Loss: 0.4896\tAdversary Loss: 0.6321\tC(x): 0.5827\tA(x, y): 0.6384\n",
      "Epoch: [3/50] Batch: [201/268]\tClassifier_Loss: 0.5303\tAdversary Loss: 0.6063\tC(x): 0.5739\tA(x, y): 0.6389\n",
      "Epoch: [4/50] Batch: [1/268]\tClassifier_Loss: 0.4292\tAdversary Loss: 0.6666\tC(x): 0.5710\tA(x, y): 0.6389\n",
      "Learning rate of the classifier model is now set to 0.00096\n",
      "Learning rate of the adversary model is now set to 0.00096\n",
      "Epoch: [4/50] Batch: [201/268]\tClassifier_Loss: 0.4860\tAdversary Loss: 0.6432\tC(x): 0.5577\tA(x, y): 0.6387\n",
      "Epoch: [5/50] Batch: [1/268]\tClassifier_Loss: 0.4826\tAdversary Loss: 0.6178\tC(x): 0.5535\tA(x, y): 0.6384\n",
      "Epoch: [5/50] Batch: [201/268]\tClassifier_Loss: 0.4653\tAdversary Loss: 0.6191\tC(x): 0.5430\tA(x, y): 0.6380\n",
      "Epoch: [6/50] Batch: [1/268]\tClassifier_Loss: 0.5256\tAdversary Loss: 0.6482\tC(x): 0.5409\tA(x, y): 0.6379\n",
      "Epoch: [6/50] Batch: [201/268]\tClassifier_Loss: 0.5072\tAdversary Loss: 0.6534\tC(x): 0.5351\tA(x, y): 0.6377\n",
      "Epoch: [7/50] Batch: [1/268]\tClassifier_Loss: 0.5559\tAdversary Loss: 0.6195\tC(x): 0.5338\tA(x, y): 0.6376\n",
      "Epoch: [7/50] Batch: [201/268]\tClassifier_Loss: 0.5053\tAdversary Loss: 0.6481\tC(x): 0.5297\tA(x, y): 0.6373\n",
      "Epoch: [8/50] Batch: [1/268]\tClassifier_Loss: 0.4485\tAdversary Loss: 0.6793\tC(x): 0.5290\tA(x, y): 0.6373\n",
      "Learning rate of the classifier model is now set to 0.0009216\n",
      "Learning rate of the adversary model is now set to 0.0009216\n",
      "Epoch: [8/50] Batch: [201/268]\tClassifier_Loss: 0.4751\tAdversary Loss: 0.6224\tC(x): 0.5265\tA(x, y): 0.6371\n",
      "Epoch: [9/50] Batch: [1/268]\tClassifier_Loss: 0.5447\tAdversary Loss: 0.6453\tC(x): 0.5256\tA(x, y): 0.6371\n",
      "Epoch: [9/50] Batch: [201/268]\tClassifier_Loss: 0.5600\tAdversary Loss: 0.5957\tC(x): 0.5236\tA(x, y): 0.6369\n",
      "Epoch: [10/50] Batch: [1/268]\tClassifier_Loss: 0.4983\tAdversary Loss: 0.6499\tC(x): 0.5232\tA(x, y): 0.6370\n",
      "Epoch: [10/50] Batch: [201/268]\tClassifier_Loss: 0.5969\tAdversary Loss: 0.6037\tC(x): 0.5226\tA(x, y): 0.6369\n",
      "Epoch: [11/50] Batch: [1/268]\tClassifier_Loss: 0.5488\tAdversary Loss: 0.6586\tC(x): 0.5223\tA(x, y): 0.6369\n",
      "Epoch: [11/50] Batch: [201/268]\tClassifier_Loss: 0.5220\tAdversary Loss: 0.6229\tC(x): 0.5214\tA(x, y): 0.6368\n",
      "Epoch: [12/50] Batch: [1/268]\tClassifier_Loss: 0.5177\tAdversary Loss: 0.6224\tC(x): 0.5212\tA(x, y): 0.6368\n",
      "Learning rate of the classifier model is now set to 0.0008847359999999999\n",
      "Learning rate of the adversary model is now set to 0.0008847359999999999\n",
      "Epoch: [12/50] Batch: [201/268]\tClassifier_Loss: 0.5293\tAdversary Loss: 0.6449\tC(x): 0.5208\tA(x, y): 0.6367\n",
      "Epoch: [13/50] Batch: [1/268]\tClassifier_Loss: 0.4639\tAdversary Loss: 0.6642\tC(x): 0.5201\tA(x, y): 0.6367\n",
      "Epoch: [13/50] Batch: [201/268]\tClassifier_Loss: 0.5680\tAdversary Loss: 0.6270\tC(x): 0.5191\tA(x, y): 0.6366\n",
      "Epoch: [14/50] Batch: [1/268]\tClassifier_Loss: 0.4604\tAdversary Loss: 0.6602\tC(x): 0.5192\tA(x, y): 0.6366\n",
      "Epoch: [14/50] Batch: [201/268]\tClassifier_Loss: 0.4221\tAdversary Loss: 0.6489\tC(x): 0.5186\tA(x, y): 0.6366\n",
      "Epoch: [15/50] Batch: [1/268]\tClassifier_Loss: 0.4110\tAdversary Loss: 0.6377\tC(x): 0.5186\tA(x, y): 0.6366\n",
      "Epoch: [15/50] Batch: [201/268]\tClassifier_Loss: 0.5025\tAdversary Loss: 0.6153\tC(x): 0.5180\tA(x, y): 0.6365\n",
      "Learning rate of the classifier model is now set to 0.0008493465599999999\n",
      "Learning rate of the adversary model is now set to 0.0008493465599999999\n",
      "Epoch: [16/50] Batch: [1/268]\tClassifier_Loss: 0.5442\tAdversary Loss: 0.5986\tC(x): 0.5180\tA(x, y): 0.6365\n",
      "Epoch: [16/50] Batch: [201/268]\tClassifier_Loss: 0.5796\tAdversary Loss: 0.6370\tC(x): 0.5179\tA(x, y): 0.6364\n",
      "Epoch: [17/50] Batch: [1/268]\tClassifier_Loss: 0.5720\tAdversary Loss: 0.6180\tC(x): 0.5176\tA(x, y): 0.6364\n",
      "Epoch: [17/50] Batch: [201/268]\tClassifier_Loss: 0.5505\tAdversary Loss: 0.6336\tC(x): 0.5170\tA(x, y): 0.6364\n",
      "Epoch: [18/50] Batch: [1/268]\tClassifier_Loss: 0.5697\tAdversary Loss: 0.6227\tC(x): 0.5167\tA(x, y): 0.6364\n",
      "Epoch: [18/50] Batch: [201/268]\tClassifier_Loss: 0.4673\tAdversary Loss: 0.6245\tC(x): 0.5159\tA(x, y): 0.6364\n",
      "Epoch: [19/50] Batch: [1/268]\tClassifier_Loss: 0.4570\tAdversary Loss: 0.6373\tC(x): 0.5159\tA(x, y): 0.6364\n",
      "Learning rate of the classifier model is now set to 0.0008153726975999999\n",
      "Learning rate of the adversary model is now set to 0.0008153726975999999\n",
      "Epoch: [19/50] Batch: [201/268]\tClassifier_Loss: 0.5531\tAdversary Loss: 0.6747\tC(x): 0.5156\tA(x, y): 0.6363\n",
      "Epoch: [20/50] Batch: [1/268]\tClassifier_Loss: 0.5226\tAdversary Loss: 0.6133\tC(x): 0.5155\tA(x, y): 0.6363\n",
      "Epoch: [20/50] Batch: [201/268]\tClassifier_Loss: 0.5447\tAdversary Loss: 0.6679\tC(x): 0.5149\tA(x, y): 0.6363\n",
      "Epoch: [21/50] Batch: [1/268]\tClassifier_Loss: 0.4841\tAdversary Loss: 0.6380\tC(x): 0.5149\tA(x, y): 0.6363\n",
      "Epoch: [21/50] Batch: [201/268]\tClassifier_Loss: 0.4608\tAdversary Loss: 0.6798\tC(x): 0.5146\tA(x, y): 0.6363\n",
      "Epoch: [22/50] Batch: [1/268]\tClassifier_Loss: 0.5401\tAdversary Loss: 0.6288\tC(x): 0.5145\tA(x, y): 0.6363\n",
      "Epoch: [22/50] Batch: [201/268]\tClassifier_Loss: 0.4878\tAdversary Loss: 0.6389\tC(x): 0.5143\tA(x, y): 0.6363\n",
      "Epoch: [23/50] Batch: [1/268]\tClassifier_Loss: 0.5555\tAdversary Loss: 0.6411\tC(x): 0.5143\tA(x, y): 0.6363\n",
      "Learning rate of the classifier model is now set to 0.0007827577896959999\n",
      "Learning rate of the adversary model is now set to 0.0007827577896959999\n",
      "Epoch: [23/50] Batch: [201/268]\tClassifier_Loss: 0.4985\tAdversary Loss: 0.6627\tC(x): 0.5141\tA(x, y): 0.6363\n",
      "Epoch: [24/50] Batch: [1/268]\tClassifier_Loss: 0.5447\tAdversary Loss: 0.6230\tC(x): 0.5141\tA(x, y): 0.6363\n",
      "Epoch: [24/50] Batch: [201/268]\tClassifier_Loss: 0.4614\tAdversary Loss: 0.6559\tC(x): 0.5140\tA(x, y): 0.6363\n",
      "Epoch: [25/50] Batch: [1/268]\tClassifier_Loss: 0.4785\tAdversary Loss: 0.6304\tC(x): 0.5140\tA(x, y): 0.6362\n",
      "Epoch: [25/50] Batch: [201/268]\tClassifier_Loss: 0.4535\tAdversary Loss: 0.6430\tC(x): 0.5142\tA(x, y): 0.6362\n",
      "Epoch: [26/50] Batch: [1/268]\tClassifier_Loss: 0.5136\tAdversary Loss: 0.6604\tC(x): 0.5141\tA(x, y): 0.6362\n",
      "Epoch: [26/50] Batch: [201/268]\tClassifier_Loss: 0.5455\tAdversary Loss: 0.6352\tC(x): 0.5142\tA(x, y): 0.6362\n",
      "Epoch: [27/50] Batch: [1/268]\tClassifier_Loss: 0.5254\tAdversary Loss: 0.6337\tC(x): 0.5141\tA(x, y): 0.6362\n",
      "Learning rate of the classifier model is now set to 0.0007514474781081599\n",
      "Learning rate of the adversary model is now set to 0.0007514474781081599\n",
      "Epoch: [27/50] Batch: [201/268]\tClassifier_Loss: 0.4636\tAdversary Loss: 0.6529\tC(x): 0.5140\tA(x, y): 0.6362\n",
      "Epoch: [28/50] Batch: [1/268]\tClassifier_Loss: 0.5026\tAdversary Loss: 0.6443\tC(x): 0.5141\tA(x, y): 0.6362\n",
      "Epoch: [28/50] Batch: [201/268]\tClassifier_Loss: 0.4901\tAdversary Loss: 0.6348\tC(x): 0.5141\tA(x, y): 0.6362\n",
      "Epoch: [29/50] Batch: [1/268]\tClassifier_Loss: 0.5381\tAdversary Loss: 0.6310\tC(x): 0.5141\tA(x, y): 0.6362\n",
      "Epoch: [29/50] Batch: [201/268]\tClassifier_Loss: 0.5146\tAdversary Loss: 0.6259\tC(x): 0.5143\tA(x, y): 0.6362\n",
      "Epoch: [30/50] Batch: [1/268]\tClassifier_Loss: 0.7380\tAdversary Loss: 0.6387\tC(x): 0.5144\tA(x, y): 0.6362\n",
      "Epoch: [30/50] Batch: [201/268]\tClassifier_Loss: 0.4578\tAdversary Loss: 0.6351\tC(x): 0.5145\tA(x, y): 0.6362\n",
      "Learning rate of the classifier model is now set to 0.0007213895789838334\n",
      "Learning rate of the adversary model is now set to 0.0007213895789838334\n",
      "Epoch: [31/50] Batch: [1/268]\tClassifier_Loss: 0.6091\tAdversary Loss: 0.6448\tC(x): 0.5145\tA(x, y): 0.6362\n",
      "Epoch: [31/50] Batch: [201/268]\tClassifier_Loss: 0.4958\tAdversary Loss: 0.6285\tC(x): 0.5146\tA(x, y): 0.6362\n",
      "Epoch: [32/50] Batch: [1/268]\tClassifier_Loss: 0.5130\tAdversary Loss: 0.6534\tC(x): 0.5148\tA(x, y): 0.6362\n",
      "Epoch: [32/50] Batch: [201/268]\tClassifier_Loss: 0.5432\tAdversary Loss: 0.6101\tC(x): 0.5150\tA(x, y): 0.6362\n",
      "Epoch: [33/50] Batch: [1/268]\tClassifier_Loss: 0.6127\tAdversary Loss: 0.6054\tC(x): 0.5150\tA(x, y): 0.6362\n",
      "Epoch: [33/50] Batch: [201/268]\tClassifier_Loss: 0.4987\tAdversary Loss: 0.6738\tC(x): 0.5151\tA(x, y): 0.6362\n",
      "Epoch: [34/50] Batch: [1/268]\tClassifier_Loss: 0.7068\tAdversary Loss: 0.6704\tC(x): 0.5152\tA(x, y): 0.6362\n",
      "Learning rate of the classifier model is now set to 0.0006925339958244801\n",
      "Learning rate of the adversary model is now set to 0.0006925339958244801\n",
      "Epoch: [34/50] Batch: [201/268]\tClassifier_Loss: 0.6185\tAdversary Loss: 0.6503\tC(x): 0.5154\tA(x, y): 0.6362\n",
      "Epoch: [35/50] Batch: [1/268]\tClassifier_Loss: 0.4779\tAdversary Loss: 0.6332\tC(x): 0.5156\tA(x, y): 0.6362\n",
      "Epoch: [35/50] Batch: [201/268]\tClassifier_Loss: 0.4600\tAdversary Loss: 0.6446\tC(x): 0.5159\tA(x, y): 0.6362\n",
      "Epoch: [36/50] Batch: [1/268]\tClassifier_Loss: 0.5876\tAdversary Loss: 0.6538\tC(x): 0.5160\tA(x, y): 0.6362\n",
      "Epoch: [36/50] Batch: [201/268]\tClassifier_Loss: 0.5521\tAdversary Loss: 0.6264\tC(x): 0.5163\tA(x, y): 0.6362\n",
      "Epoch: [37/50] Batch: [1/268]\tClassifier_Loss: 0.5901\tAdversary Loss: 0.6119\tC(x): 0.5163\tA(x, y): 0.6362\n",
      "Epoch: [37/50] Batch: [201/268]\tClassifier_Loss: 0.4600\tAdversary Loss: 0.6600\tC(x): 0.5166\tA(x, y): 0.6362\n",
      "Epoch: [38/50] Batch: [1/268]\tClassifier_Loss: 0.5514\tAdversary Loss: 0.6316\tC(x): 0.5168\tA(x, y): 0.6362\n",
      "Learning rate of the classifier model is now set to 0.0006648326359915007\n",
      "Learning rate of the adversary model is now set to 0.0006648326359915007\n",
      "Epoch: [38/50] Batch: [201/268]\tClassifier_Loss: 0.4755\tAdversary Loss: 0.6435\tC(x): 0.5171\tA(x, y): 0.6363\n",
      "Epoch: [39/50] Batch: [1/268]\tClassifier_Loss: 0.5331\tAdversary Loss: 0.6237\tC(x): 0.5172\tA(x, y): 0.6362\n",
      "Epoch: [39/50] Batch: [201/268]\tClassifier_Loss: 0.4235\tAdversary Loss: 0.6488\tC(x): 0.5175\tA(x, y): 0.6362\n",
      "Epoch: [40/50] Batch: [1/268]\tClassifier_Loss: 0.6221\tAdversary Loss: 0.6430\tC(x): 0.5175\tA(x, y): 0.6362\n",
      "Epoch: [40/50] Batch: [201/268]\tClassifier_Loss: 0.5646\tAdversary Loss: 0.6545\tC(x): 0.5180\tA(x, y): 0.6362\n",
      "Epoch: [41/50] Batch: [1/268]\tClassifier_Loss: 0.5621\tAdversary Loss: 0.6437\tC(x): 0.5180\tA(x, y): 0.6363\n",
      "Epoch: [41/50] Batch: [201/268]\tClassifier_Loss: 0.4595\tAdversary Loss: 0.6712\tC(x): 0.5182\tA(x, y): 0.6363\n",
      "Epoch: [42/50] Batch: [1/268]\tClassifier_Loss: 0.5923\tAdversary Loss: 0.6438\tC(x): 0.5183\tA(x, y): 0.6363\n",
      "Learning rate of the classifier model is now set to 0.0006382393305518408\n",
      "Learning rate of the adversary model is now set to 0.0006382393305518408\n",
      "Epoch: [42/50] Batch: [201/268]\tClassifier_Loss: 0.5314\tAdversary Loss: 0.6322\tC(x): 0.5186\tA(x, y): 0.6363\n",
      "Epoch: [43/50] Batch: [1/268]\tClassifier_Loss: 0.3623\tAdversary Loss: 0.6616\tC(x): 0.5187\tA(x, y): 0.6363\n",
      "Epoch: [43/50] Batch: [201/268]\tClassifier_Loss: 0.5243\tAdversary Loss: 0.6462\tC(x): 0.5188\tA(x, y): 0.6363\n",
      "Epoch: [44/50] Batch: [1/268]\tClassifier_Loss: 0.5600\tAdversary Loss: 0.6068\tC(x): 0.5189\tA(x, y): 0.6363\n",
      "Epoch: [44/50] Batch: [201/268]\tClassifier_Loss: 0.5147\tAdversary Loss: 0.6168\tC(x): 0.5192\tA(x, y): 0.6363\n",
      "Epoch: [45/50] Batch: [1/268]\tClassifier_Loss: 0.5901\tAdversary Loss: 0.6120\tC(x): 0.5194\tA(x, y): 0.6363\n",
      "Epoch: [45/50] Batch: [201/268]\tClassifier_Loss: 0.6447\tAdversary Loss: 0.6278\tC(x): 0.5196\tA(x, y): 0.6363\n",
      "Learning rate of the classifier model is now set to 0.0006127097573297671\n",
      "Learning rate of the adversary model is now set to 0.0006127097573297671\n",
      "Epoch: [46/50] Batch: [1/268]\tClassifier_Loss: 0.6275\tAdversary Loss: 0.6061\tC(x): 0.5197\tA(x, y): 0.6363\n",
      "Epoch: [46/50] Batch: [201/268]\tClassifier_Loss: 0.5800\tAdversary Loss: 0.6425\tC(x): 0.5200\tA(x, y): 0.6363\n",
      "Epoch: [47/50] Batch: [1/268]\tClassifier_Loss: 0.4950\tAdversary Loss: 0.6668\tC(x): 0.5201\tA(x, y): 0.6363\n",
      "Epoch: [47/50] Batch: [201/268]\tClassifier_Loss: 0.4874\tAdversary Loss: 0.6297\tC(x): 0.5206\tA(x, y): 0.6363\n",
      "Epoch: [48/50] Batch: [1/268]\tClassifier_Loss: 0.5575\tAdversary Loss: 0.6411\tC(x): 0.5207\tA(x, y): 0.6363\n",
      "Epoch: [48/50] Batch: [201/268]\tClassifier_Loss: 0.5183\tAdversary Loss: 0.6538\tC(x): 0.5211\tA(x, y): 0.6363\n",
      "Epoch: [49/50] Batch: [1/268]\tClassifier_Loss: 0.5394\tAdversary Loss: 0.6247\tC(x): 0.5213\tA(x, y): 0.6363\n",
      "Learning rate of the classifier model is now set to 0.0005882013670365765\n",
      "Learning rate of the adversary model is now set to 0.0005882013670365765\n",
      "Epoch: [49/50] Batch: [201/268]\tClassifier_Loss: 0.5883\tAdversary Loss: 0.6356\tC(x): 0.5215\tA(x, y): 0.6363\n",
      "Epoch: [50/50] Batch: [1/268]\tClassifier_Loss: 0.6350\tAdversary Loss: 0.6299\tC(x): 0.5215\tA(x, y): 0.6363\n",
      "Epoch: [50/50] Batch: [201/268]\tClassifier_Loss: 0.5044\tAdversary Loss: 0.6559\tC(x): 0.5218\tA(x, y): 0.6363\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<aif360.pytorch.inprocessing.adversarial_debiasing.AdversarialDebiasing at 0x19173354648>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "debiased_model.fit(dataset_orig_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tZF-Kih6OUWp"
   },
   "outputs": [],
   "source": [
    "# Apply the plain model to test data\n",
    "dataset_debiasing_train = debiased_model.predict(dataset_orig_train)\n",
    "dataset_debiasing_test = debiased_model.predict(dataset_orig_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "t1vZGQm0OUWw",
    "outputId": "af8617b6-4891-4a71-8ca4-4d5ae559c311"
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Plain model - without debiasing - dataset metrics"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: Difference in mean outcomes between unprivileged and privileged groups = -0.217658\n",
      "Test set: Difference in mean outcomes between unprivileged and privileged groups = -0.210708\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Model - with debiasing - dataset metrics"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: Difference in mean outcomes between unprivileged and privileged groups = 0.000000\n",
      "Test set: Difference in mean outcomes between unprivileged and privileged groups = -0.000101\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Plain model - without debiasing - classification metrics"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Classification accuracy = 0.805364\n",
      "Test set: Balanced classification accuracy = 0.661739\n",
      "Test set: Disparate impact = 0.000000\n",
      "Test set: Equal opportunity difference = -0.455312\n",
      "Test set: Average odds difference = -0.280433\n",
      "Test set: Theil_index = 0.176247\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Model - with debiasing - classification metrics"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Classification accuracy = 0.762984\n",
      "Test set: Balanced classification accuracy = 0.500144\n",
      "Test set: Disparate impact = 0.000000\n",
      "Test set: Equal opportunity difference = -0.000337\n",
      "Test set: Average odds difference = -0.000169\n",
      "Test set: Theil_index = 0.270519\n"
     ]
    }
   ],
   "source": [
    "# Metrics for the dataset from plain model (without debiasing)\n",
    "display(Markdown(\"#### Plain model - without debiasing - dataset metrics\"))\n",
    "print(\"Train set: Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_dataset_nodebiasing_train.mean_difference())\n",
    "print(\"Test set: Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_dataset_nodebiasing_test.mean_difference())\n",
    "\n",
    "# Metrics for the dataset from model with debiasing\n",
    "display(Markdown(\"#### Model - with debiasing - dataset metrics\"))\n",
    "metric_dataset_debiasing_train = BinaryLabelDatasetMetric(dataset_debiasing_train, \n",
    "                                             unprivileged_groups=unprivileged_groups,\n",
    "                                             privileged_groups=privileged_groups)\n",
    "\n",
    "print(\"Train set: Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_dataset_debiasing_train.mean_difference())\n",
    "\n",
    "metric_dataset_debiasing_test = BinaryLabelDatasetMetric(dataset_debiasing_test, \n",
    "                                             unprivileged_groups=unprivileged_groups,\n",
    "                                             privileged_groups=privileged_groups)\n",
    "\n",
    "print(\"Test set: Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_dataset_debiasing_test.mean_difference())\n",
    "\n",
    "\n",
    "\n",
    "display(Markdown(\"#### Plain model - without debiasing - classification metrics\"))\n",
    "print(\"Test set: Classification accuracy = %f\" % classified_metric_nodebiasing_test.accuracy())\n",
    "TPR = classified_metric_nodebiasing_test.true_positive_rate()\n",
    "TNR = classified_metric_nodebiasing_test.true_negative_rate()\n",
    "bal_acc_nodebiasing_test = 0.5*(TPR+TNR)\n",
    "print(\"Test set: Balanced classification accuracy = %f\" % bal_acc_nodebiasing_test)\n",
    "print(\"Test set: Disparate impact = %f\" % classified_metric_nodebiasing_test.disparate_impact())\n",
    "print(\"Test set: Equal opportunity difference = %f\" % classified_metric_nodebiasing_test.equal_opportunity_difference())\n",
    "print(\"Test set: Average odds difference = %f\" % classified_metric_nodebiasing_test.average_odds_difference())\n",
    "print(\"Test set: Theil_index = %f\" % classified_metric_nodebiasing_test.theil_index())\n",
    "\n",
    "\n",
    "\n",
    "display(Markdown(\"#### Model - with debiasing - classification metrics\"))\n",
    "classified_metric_debiasing_test = ClassificationMetric(dataset_orig_test, \n",
    "                                                 dataset_debiasing_test,\n",
    "                                                 unprivileged_groups=unprivileged_groups,\n",
    "                                                 privileged_groups=privileged_groups)\n",
    "print(\"Test set: Classification accuracy = %f\" % classified_metric_debiasing_test.accuracy())\n",
    "TPR = classified_metric_debiasing_test.true_positive_rate()\n",
    "TNR = classified_metric_debiasing_test.true_negative_rate()\n",
    "bal_acc_debiasing_test = 0.5*(TPR+TNR)\n",
    "print(\"Test set: Balanced classification accuracy = %f\" % bal_acc_debiasing_test)\n",
    "print(\"Test set: Disparate impact = %f\" % classified_metric_debiasing_test.disparate_impact())\n",
    "print(\"Test set: Equal opportunity difference = %f\" % classified_metric_debiasing_test.equal_opportunity_difference())\n",
    "print(\"Test set: Average odds difference = %f\" % classified_metric_debiasing_test.average_odds_difference())\n",
    "print(\"Test set: Theil_index = %f\" % classified_metric_debiasing_test.theil_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Demonstration of AdversialDebiasing trainig process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights(layer):\n",
    "    r\"\"\"Initialize layer weights and biases if it has any and the chosen initializer\n",
    "    is valid. Can be applied on any layer and will only initialize parametric layers.\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        layer.__getattr__('weight')\n",
    "        _has_weight = True\n",
    "    except:\n",
    "        _has_weight = False\n",
    "\n",
    "    try:\n",
    "        layer.__getattr__('bias')\n",
    "        _has_bias = True\n",
    "    except:\n",
    "        _has_bias = False\n",
    "\n",
    "    if _has_weight:\n",
    "        torch.nn.init.xavier_uniform_(layer.weight.data)\n",
    "    if _has_bias:\n",
    "        try:\n",
    "            torch.nn.init.xavier_uniform_(layer.bias.data)\n",
    "        except:\n",
    "            layer.bias.data.fill_(0.01)\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 144\n",
    "num_epochs = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ClassifierModel(\n",
       "  (ann): Sequential(\n",
       "    (0): Linear(in_features=18, out_features=200, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "    (3): Linear(in_features=200, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(seed)\n",
    "classifier = ClassifierModel(default_classifier_ann(18,[200],[0.5]), torch.sigmoid)\n",
    "classifier.apply(init_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdversaryModel(\n",
       "  (ann): Sequential(\n",
       "    (0): Linear(in_features=18, out_features=200, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "    (3): Linear(in_features=200, out_features=1, bias=True)\n",
       "  )\n",
       "  (s): Sigmoid()\n",
       "  (encoder): Linear(in_features=3, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(seed)\n",
    "adversary = AdversaryModel(default_classifier_ann(18,[200],[0.5]))\n",
    "adversary.apply(init_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(seed)\n",
    "protected_attribute_index = dataset_orig_train.protected_attribute_names.index('sex')\n",
    "train_dataset = torch.utils.data.TensorDataset(\n",
    "    torch.from_numpy(dataset_orig_train.features).float(),\n",
    "    torch.from_numpy(dataset_orig_train.labels).float(),\n",
    "    torch.from_numpy(dataset_orig_train.protected_attributes[:, protected_attribute_index].\\\n",
    "    reshape(dataset_orig_train.protected_attributes.shape[0], -1)).float()\n",
    ")\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=128, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from math import ceil\n",
    "num_train_samples, features_dim = np.shape(dataset_orig_train.features)\n",
    "global_steps = num_epochs * ceil(num_train_samples / 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(seed)\n",
    "classifier_optim = torch.optim.Adam([p for p in classifier.parameters() if p.requires_grad], lr=0.001)\n",
    "classifier_lr_scheduler = StaircaseExponentialLR(classifier_optim, global_steps, 0.001, 100, 0.96, None, True, True)\n",
    "adversary_optim = torch.optim.Adam([p for p in adversary.parameters() if p.requires_grad], lr=0.001)\n",
    "adversary_lr_scheduler = StaircaseExponentialLR(adversary_optim, global_steps, 0.001, 100, 0.96, None, True, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize = lambda x: x / (torch.norm(x) + np.finfo(np.float32).tiny)\n",
    "classifier_criterion = torch.nn.BCELoss(reduction=\"mean\")\n",
    "adversary_criterion = torch.nn.BCELoss(reduction=\"mean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate of the classifier model is now set to 0.001\n",
      "Learning rate of the adversary model is now set to 0.001\n",
      "Epoch: [1/50] Batch: [1/268]\tClassifier_Loss: 0.6972\tAdversary Loss: 0.9044\tC(x): 0.6972\tA(x, y): 0.9044\n",
      "Learning rate of the classifier model is now set to 0.00096\n",
      "Learning rate of the adversary model is now set to 0.00096\n",
      "Learning rate of the classifier model is now set to 0.0009216\n",
      "Learning rate of the adversary model is now set to 0.0009216\n",
      "Epoch: [1/50] Batch: [201/268]\tClassifier_Loss: 4.7981\tAdversary Loss: 0.8756\tC(x): 4.4480\tA(x, y): 0.9084\n",
      "Epoch: [2/50] Batch: [1/268]\tClassifier_Loss: 3.3101\tAdversary Loss: 0.7934\tC(x): 4.3962\tA(x, y): 0.8814\n",
      "Learning rate of the classifier model is now set to 0.0008847359999999999\n",
      "Learning rate of the adversary model is now set to 0.0008847359999999999\n",
      "Learning rate of the classifier model is now set to 0.0008493465599999999\n",
      "Learning rate of the adversary model is now set to 0.0008493465599999999\n",
      "Epoch: [2/50] Batch: [201/268]\tClassifier_Loss: 2.4406\tAdversary Loss: 0.7131\tC(x): 3.7947\tA(x, y): 0.8153\n",
      "Learning rate of the classifier model is now set to 0.0008153726975999999\n",
      "Learning rate of the adversary model is now set to 0.0008153726975999999\n",
      "Epoch: [3/50] Batch: [1/268]\tClassifier_Loss: 2.3382\tAdversary Loss: 0.6657\tC(x): 3.5909\tA(x, y): 0.7984\n",
      "Learning rate of the classifier model is now set to 0.0007827577896959999\n",
      "Learning rate of the adversary model is now set to 0.0007827577896959999\n",
      "Learning rate of the classifier model is now set to 0.0007514474781081599\n",
      "Learning rate of the adversary model is now set to 0.0007514474781081599\n",
      "Epoch: [3/50] Batch: [201/268]\tClassifier_Loss: 1.1565\tAdversary Loss: 0.6311\tC(x): 3.0387\tA(x, y): 0.7598\n",
      "Learning rate of the classifier model is now set to 0.0007213895789838334\n",
      "Learning rate of the adversary model is now set to 0.0007213895789838334\n",
      "Epoch: [4/50] Batch: [1/268]\tClassifier_Loss: 0.9930\tAdversary Loss: 0.6405\tC(x): 2.8738\tA(x, y): 0.7495\n",
      "Learning rate of the classifier model is now set to 0.0006925339958244801\n",
      "Learning rate of the adversary model is now set to 0.0006925339958244801\n",
      "Learning rate of the classifier model is now set to 0.0006648326359915007\n",
      "Learning rate of the adversary model is now set to 0.0006648326359915007\n",
      "Epoch: [4/50] Batch: [201/268]\tClassifier_Loss: 0.8186\tAdversary Loss: 0.6095\tC(x): 2.4664\tA(x, y): 0.7259\n",
      "Epoch: [5/50] Batch: [1/268]\tClassifier_Loss: 0.6519\tAdversary Loss: 0.6032\tC(x): 2.3546\tA(x, y): 0.7197\n",
      "Learning rate of the classifier model is now set to 0.0006382393305518408\n",
      "Learning rate of the adversary model is now set to 0.0006382393305518408\n",
      "Learning rate of the classifier model is now set to 0.0006127097573297671\n",
      "Learning rate of the adversary model is now set to 0.0006127097573297671\n",
      "Epoch: [5/50] Batch: [201/268]\tClassifier_Loss: 0.5616\tAdversary Loss: 0.6743\tC(x): 2.0798\tA(x, y): 0.7051\n",
      "Learning rate of the classifier model is now set to 0.0005882013670365765\n",
      "Learning rate of the adversary model is now set to 0.0005882013670365765\n",
      "Epoch: [6/50] Batch: [1/268]\tClassifier_Loss: 0.5815\tAdversary Loss: 0.6090\tC(x): 2.0037\tA(x, y): 0.7007\n",
      "Learning rate of the classifier model is now set to 0.0005646733123551134\n",
      "Learning rate of the adversary model is now set to 0.0005646733123551134\n",
      "Learning rate of the classifier model is now set to 0.0005420863798609088\n",
      "Learning rate of the adversary model is now set to 0.0005420863798609088\n",
      "Epoch: [6/50] Batch: [201/268]\tClassifier_Loss: 0.6924\tAdversary Loss: 0.6343\tC(x): 1.8195\tA(x, y): 0.6907\n",
      "Learning rate of the classifier model is now set to 0.0005204029246664724\n",
      "Learning rate of the adversary model is now set to 0.0005204029246664724\n",
      "Epoch: [7/50] Batch: [1/268]\tClassifier_Loss: 0.5712\tAdversary Loss: 0.6483\tC(x): 1.7671\tA(x, y): 0.6878\n",
      "Learning rate of the classifier model is now set to 0.0004995868076798134\n",
      "Learning rate of the adversary model is now set to 0.0004995868076798134\n",
      "Learning rate of the classifier model is now set to 0.0004796033353726209\n",
      "Learning rate of the adversary model is now set to 0.0004796033353726209\n",
      "Epoch: [7/50] Batch: [201/268]\tClassifier_Loss: 0.5447\tAdversary Loss: 0.6143\tC(x): 1.6360\tA(x, y): 0.6806\n",
      "Epoch: [8/50] Batch: [1/268]\tClassifier_Loss: 0.6792\tAdversary Loss: 0.5897\tC(x): 1.5976\tA(x, y): 0.6783\n",
      "Learning rate of the classifier model is now set to 0.00046041920195771606\n",
      "Learning rate of the adversary model is now set to 0.00046041920195771606\n",
      "Learning rate of the classifier model is now set to 0.00044200243387940743\n",
      "Learning rate of the adversary model is now set to 0.00044200243387940743\n",
      "Epoch: [8/50] Batch: [201/268]\tClassifier_Loss: 0.6811\tAdversary Loss: 0.5884\tC(x): 1.4988\tA(x, y): 0.6726\n",
      "Learning rate of the classifier model is now set to 0.0004243223365242311\n",
      "Learning rate of the adversary model is now set to 0.0004243223365242311\n",
      "Epoch: [9/50] Batch: [1/268]\tClassifier_Loss: 0.5912\tAdversary Loss: 0.6316\tC(x): 1.4695\tA(x, y): 0.6711\n",
      "Learning rate of the classifier model is now set to 0.00040734944306326185\n",
      "Learning rate of the adversary model is now set to 0.00040734944306326185\n",
      "Learning rate of the classifier model is now set to 0.00039105546534073135\n",
      "Learning rate of the adversary model is now set to 0.00039105546534073135\n",
      "Epoch: [9/50] Batch: [201/268]\tClassifier_Loss: 0.4545\tAdversary Loss: 0.6665\tC(x): 1.3928\tA(x, y): 0.6668\n",
      "Learning rate of the classifier model is now set to 0.0003754132467271021\n",
      "Learning rate of the adversary model is now set to 0.0003754132467271021\n",
      "Epoch: [10/50] Batch: [1/268]\tClassifier_Loss: 0.5378\tAdversary Loss: 0.6768\tC(x): 1.3695\tA(x, y): 0.6653\n",
      "Learning rate of the classifier model is now set to 0.000360396716858018\n",
      "Learning rate of the adversary model is now set to 0.000360396716858018\n",
      "Learning rate of the classifier model is now set to 0.00034598084818369723\n",
      "Learning rate of the adversary model is now set to 0.00034598084818369723\n",
      "Epoch: [10/50] Batch: [201/268]\tClassifier_Loss: 0.5184\tAdversary Loss: 0.6534\tC(x): 1.3083\tA(x, y): 0.6617\n",
      "Epoch: [11/50] Batch: [1/268]\tClassifier_Loss: 0.4851\tAdversary Loss: 0.6287\tC(x): 1.2897\tA(x, y): 0.6605\n",
      "Learning rate of the classifier model is now set to 0.0003321416142563494\n",
      "Learning rate of the adversary model is now set to 0.0003321416142563494\n",
      "Learning rate of the classifier model is now set to 0.0003188559496860954\n",
      "Learning rate of the adversary model is now set to 0.0003188559496860954\n",
      "Epoch: [11/50] Batch: [201/268]\tClassifier_Loss: 0.5589\tAdversary Loss: 0.6410\tC(x): 1.2395\tA(x, y): 0.6575\n",
      "Learning rate of the classifier model is now set to 0.00030610171169865154\n",
      "Learning rate of the adversary model is now set to 0.00030610171169865154\n",
      "Epoch: [12/50] Batch: [1/268]\tClassifier_Loss: 0.5899\tAdversary Loss: 0.5548\tC(x): 1.2239\tA(x, y): 0.6565\n",
      "Learning rate of the classifier model is now set to 0.0002938576432307055\n",
      "Learning rate of the adversary model is now set to 0.0002938576432307055\n",
      "Learning rate of the classifier model is now set to 0.00028210333750147725\n",
      "Learning rate of the adversary model is now set to 0.00028210333750147725\n",
      "Epoch: [12/50] Batch: [201/268]\tClassifier_Loss: 0.5835\tAdversary Loss: 0.6258\tC(x): 1.1819\tA(x, y): 0.6540\n",
      "Learning rate of the classifier model is now set to 0.00027081920400141813\n",
      "Learning rate of the adversary model is now set to 0.00027081920400141813\n",
      "Epoch: [13/50] Batch: [1/268]\tClassifier_Loss: 0.4900\tAdversary Loss: 0.6534\tC(x): 1.1688\tA(x, y): 0.6532\n",
      "Learning rate of the classifier model is now set to 0.0002599864358413614\n",
      "Learning rate of the adversary model is now set to 0.0002599864358413614\n",
      "Learning rate of the classifier model is now set to 0.00024958697840770695\n",
      "Learning rate of the adversary model is now set to 0.00024958697840770695\n",
      "Epoch: [13/50] Batch: [201/268]\tClassifier_Loss: 0.5628\tAdversary Loss: 0.6074\tC(x): 1.1331\tA(x, y): 0.6509\n",
      "Epoch: [14/50] Batch: [1/268]\tClassifier_Loss: 0.5934\tAdversary Loss: 0.5853\tC(x): 1.1220\tA(x, y): 0.6503\n",
      "Learning rate of the classifier model is now set to 0.00023960349927139865\n",
      "Learning rate of the adversary model is now set to 0.00023960349927139865\n",
      "Learning rate of the classifier model is now set to 0.0002300193593005427\n",
      "Learning rate of the adversary model is now set to 0.0002300193593005427\n",
      "Epoch: [14/50] Batch: [201/268]\tClassifier_Loss: 0.5385\tAdversary Loss: 0.6398\tC(x): 1.0912\tA(x, y): 0.6484\n",
      "Learning rate of the classifier model is now set to 0.00022081858492852097\n",
      "Learning rate of the adversary model is now set to 0.00022081858492852097\n",
      "Epoch: [15/50] Batch: [1/268]\tClassifier_Loss: 0.5959\tAdversary Loss: 0.5721\tC(x): 1.0817\tA(x, y): 0.6477\n",
      "Learning rate of the classifier model is now set to 0.00021198584153138015\n",
      "Learning rate of the adversary model is now set to 0.00021198584153138015\n",
      "Learning rate of the classifier model is now set to 0.0002035064078701249\n",
      "Learning rate of the adversary model is now set to 0.0002035064078701249\n",
      "Epoch: [15/50] Batch: [201/268]\tClassifier_Loss: 0.5604\tAdversary Loss: 0.6125\tC(x): 1.0548\tA(x, y): 0.6460\n",
      "Learning rate of the classifier model is now set to 0.00019536615155531993\n",
      "Learning rate of the adversary model is now set to 0.00019536615155531993\n",
      "Epoch: [16/50] Batch: [1/268]\tClassifier_Loss: 0.6031\tAdversary Loss: 0.6162\tC(x): 1.0463\tA(x, y): 0.6455\n",
      "Learning rate of the classifier model is now set to 0.0001875515054931071\n",
      "Learning rate of the adversary model is now set to 0.0001875515054931071\n",
      "Learning rate of the classifier model is now set to 0.00018004944527338283\n",
      "Learning rate of the adversary model is now set to 0.00018004944527338283\n",
      "Epoch: [16/50] Batch: [201/268]\tClassifier_Loss: 0.5056\tAdversary Loss: 0.6231\tC(x): 1.0228\tA(x, y): 0.6440\n",
      "Epoch: [17/50] Batch: [1/268]\tClassifier_Loss: 0.4929\tAdversary Loss: 0.6116\tC(x): 1.0154\tA(x, y): 0.6434\n",
      "Learning rate of the classifier model is now set to 0.0001728474674624475\n",
      "Learning rate of the adversary model is now set to 0.0001728474674624475\n",
      "Learning rate of the classifier model is now set to 0.0001659335687639496\n",
      "Learning rate of the adversary model is now set to 0.0001659335687639496\n",
      "Epoch: [17/50] Batch: [201/268]\tClassifier_Loss: 0.6219\tAdversary Loss: 0.5858\tC(x): 0.9946\tA(x, y): 0.6421\n",
      "Learning rate of the classifier model is now set to 0.0001592962260133916\n",
      "Learning rate of the adversary model is now set to 0.0001592962260133916\n",
      "Epoch: [18/50] Batch: [1/268]\tClassifier_Loss: 0.5245\tAdversary Loss: 0.6455\tC(x): 0.9879\tA(x, y): 0.6416\n",
      "Learning rate of the classifier model is now set to 0.00015292437697285593\n",
      "Learning rate of the adversary model is now set to 0.00015292437697285593\n",
      "Learning rate of the classifier model is now set to 0.0001468074018939417\n",
      "Learning rate of the adversary model is now set to 0.0001468074018939417\n",
      "Epoch: [18/50] Batch: [201/268]\tClassifier_Loss: 0.4901\tAdversary Loss: 0.5725\tC(x): 0.9691\tA(x, y): 0.6404\n",
      "Learning rate of the classifier model is now set to 0.00014093510581818404\n",
      "Learning rate of the adversary model is now set to 0.00014093510581818404\n",
      "Epoch: [19/50] Batch: [1/268]\tClassifier_Loss: 0.4463\tAdversary Loss: 0.6882\tC(x): 0.9632\tA(x, y): 0.6399\n",
      "Learning rate of the classifier model is now set to 0.00013529770158545666\n",
      "Learning rate of the adversary model is now set to 0.00013529770158545666\n",
      "Learning rate of the classifier model is now set to 0.00012988579352203838\n",
      "Learning rate of the adversary model is now set to 0.00012988579352203838\n",
      "Epoch: [19/50] Batch: [201/268]\tClassifier_Loss: 0.4868\tAdversary Loss: 0.5772\tC(x): 0.9465\tA(x, y): 0.6387\n",
      "Epoch: [20/50] Batch: [1/268]\tClassifier_Loss: 0.4589\tAdversary Loss: 0.6077\tC(x): 0.9411\tA(x, y): 0.6384\n",
      "Learning rate of the classifier model is now set to 0.00012469036178115684\n",
      "Learning rate of the adversary model is now set to 0.00012469036178115684\n",
      "Learning rate of the classifier model is now set to 0.00011970274730991057\n",
      "Learning rate of the adversary model is now set to 0.00011970274730991057\n",
      "Epoch: [20/50] Batch: [201/268]\tClassifier_Loss: 0.5367\tAdversary Loss: 0.6141\tC(x): 0.9259\tA(x, y): 0.6372\n",
      "Learning rate of the classifier model is now set to 0.00011491463741751413\n",
      "Learning rate of the adversary model is now set to 0.00011491463741751413\n",
      "Epoch: [21/50] Batch: [1/268]\tClassifier_Loss: 0.5415\tAdversary Loss: 0.6587\tC(x): 0.9210\tA(x, y): 0.6369\n",
      "Learning rate of the classifier model is now set to 0.00011031805192081357\n",
      "Learning rate of the adversary model is now set to 0.00011031805192081357\n",
      "Learning rate of the classifier model is now set to 0.00010590532984398102\n",
      "Learning rate of the adversary model is now set to 0.00010590532984398102\n",
      "Epoch: [21/50] Batch: [201/268]\tClassifier_Loss: 0.5627\tAdversary Loss: 0.5736\tC(x): 0.9072\tA(x, y): 0.6359\n",
      "Learning rate of the classifier model is now set to 0.00010166911665022178\n",
      "Learning rate of the adversary model is now set to 0.00010166911665022178\n",
      "Epoch: [22/50] Batch: [1/268]\tClassifier_Loss: 0.5517\tAdversary Loss: 0.6233\tC(x): 0.9027\tA(x, y): 0.6356\n",
      "Learning rate of the classifier model is now set to 9.76023519842129e-05\n",
      "Learning rate of the adversary model is now set to 9.76023519842129e-05\n",
      "Learning rate of the classifier model is now set to 9.36982579048444e-05\n",
      "Learning rate of the adversary model is now set to 9.36982579048444e-05\n",
      "Epoch: [22/50] Batch: [201/268]\tClassifier_Loss: 0.4311\tAdversary Loss: 0.6411\tC(x): 0.8900\tA(x, y): 0.6346\n",
      "Epoch: [23/50] Batch: [1/268]\tClassifier_Loss: 0.6248\tAdversary Loss: 0.5752\tC(x): 0.8857\tA(x, y): 0.6343\n",
      "Learning rate of the classifier model is now set to 8.99503275886506e-05\n",
      "Learning rate of the adversary model is now set to 8.99503275886506e-05\n",
      "Learning rate of the classifier model is now set to 8.635231448510459e-05\n",
      "Learning rate of the adversary model is now set to 8.635231448510459e-05\n",
      "Epoch: [23/50] Batch: [201/268]\tClassifier_Loss: 0.4980\tAdversary Loss: 0.6305\tC(x): 0.8741\tA(x, y): 0.6335\n",
      "Learning rate of the classifier model is now set to 8.289822190570039e-05\n",
      "Learning rate of the adversary model is now set to 8.289822190570039e-05\n",
      "Epoch: [24/50] Batch: [1/268]\tClassifier_Loss: 0.4924\tAdversary Loss: 0.6234\tC(x): 0.8703\tA(x, y): 0.6332\n",
      "Learning rate of the classifier model is now set to 7.958229302947238e-05\n",
      "Learning rate of the adversary model is now set to 7.958229302947238e-05\n",
      "Learning rate of the classifier model is now set to 7.639900130829346e-05\n",
      "Learning rate of the adversary model is now set to 7.639900130829346e-05\n",
      "Epoch: [24/50] Batch: [201/268]\tClassifier_Loss: 0.4230\tAdversary Loss: 0.6122\tC(x): 0.8597\tA(x, y): 0.6324\n",
      "Learning rate of the classifier model is now set to 7.334304125596173e-05\n",
      "Learning rate of the adversary model is now set to 7.334304125596173e-05\n",
      "Epoch: [25/50] Batch: [1/268]\tClassifier_Loss: 0.5611\tAdversary Loss: 0.5821\tC(x): 0.8562\tA(x, y): 0.6321\n",
      "Learning rate of the classifier model is now set to 7.040931960572326e-05\n",
      "Learning rate of the adversary model is now set to 7.040931960572326e-05\n",
      "Learning rate of the classifier model is now set to 6.759294682149434e-05\n",
      "Learning rate of the adversary model is now set to 6.759294682149434e-05\n",
      "Epoch: [25/50] Batch: [201/268]\tClassifier_Loss: 0.6420\tAdversary Loss: 0.6171\tC(x): 0.8463\tA(x, y): 0.6313\n",
      "Learning rate of the classifier model is now set to 6.488922894863455e-05\n",
      "Learning rate of the adversary model is now set to 6.488922894863455e-05\n",
      "Epoch: [26/50] Batch: [1/268]\tClassifier_Loss: 0.5606\tAdversary Loss: 0.5969\tC(x): 0.8430\tA(x, y): 0.6311\n",
      "Learning rate of the classifier model is now set to 6.229365979068917e-05\n",
      "Learning rate of the adversary model is now set to 6.229365979068917e-05\n",
      "Learning rate of the classifier model is now set to 5.9801913399061606e-05\n",
      "Learning rate of the adversary model is now set to 5.9801913399061606e-05\n",
      "Epoch: [26/50] Batch: [201/268]\tClassifier_Loss: 0.4703\tAdversary Loss: 0.6123\tC(x): 0.8338\tA(x, y): 0.6303\n",
      "Epoch: [27/50] Batch: [1/268]\tClassifier_Loss: 0.5458\tAdversary Loss: 0.6082\tC(x): 0.8307\tA(x, y): 0.6301\n",
      "Learning rate of the classifier model is now set to 5.7409836863099135e-05\n",
      "Learning rate of the adversary model is now set to 5.7409836863099135e-05\n",
      "Learning rate of the classifier model is now set to 5.511344338857516e-05\n",
      "Learning rate of the adversary model is now set to 5.511344338857516e-05\n",
      "Epoch: [27/50] Batch: [201/268]\tClassifier_Loss: 0.5264\tAdversary Loss: 0.5608\tC(x): 0.8222\tA(x, y): 0.6294\n",
      "Learning rate of the classifier model is now set to 5.290890565303216e-05\n",
      "Learning rate of the adversary model is now set to 5.290890565303216e-05\n",
      "Epoch: [28/50] Batch: [1/268]\tClassifier_Loss: 0.5096\tAdversary Loss: 0.6383\tC(x): 0.8195\tA(x, y): 0.6292\n",
      "Learning rate of the classifier model is now set to 5.0792549426910866e-05\n",
      "Learning rate of the adversary model is now set to 5.0792549426910866e-05\n",
      "Learning rate of the classifier model is now set to 4.876084744983443e-05\n",
      "Learning rate of the adversary model is now set to 4.876084744983443e-05\n",
      "Epoch: [28/50] Batch: [201/268]\tClassifier_Loss: 0.4567\tAdversary Loss: 0.6047\tC(x): 0.8114\tA(x, y): 0.6285\n",
      "Learning rate of the classifier model is now set to 4.6810413551841054e-05\n",
      "Learning rate of the adversary model is now set to 4.6810413551841054e-05\n",
      "Epoch: [29/50] Batch: [1/268]\tClassifier_Loss: 0.5289\tAdversary Loss: 0.6073\tC(x): 0.8088\tA(x, y): 0.6283\n",
      "Learning rate of the classifier model is now set to 4.493799700976741e-05\n",
      "Learning rate of the adversary model is now set to 4.493799700976741e-05\n",
      "Learning rate of the classifier model is now set to 4.3140477129376715e-05\n",
      "Learning rate of the adversary model is now set to 4.3140477129376715e-05\n",
      "Epoch: [29/50] Batch: [201/268]\tClassifier_Loss: 0.5842\tAdversary Loss: 0.6408\tC(x): 0.8013\tA(x, y): 0.6276\n",
      "Epoch: [30/50] Batch: [1/268]\tClassifier_Loss: 0.5599\tAdversary Loss: 0.6301\tC(x): 0.7989\tA(x, y): 0.6275\n",
      "Learning rate of the classifier model is now set to 4.141485804420164e-05\n",
      "Learning rate of the adversary model is now set to 4.141485804420164e-05\n",
      "Learning rate of the classifier model is now set to 3.9758263722433575e-05\n",
      "Learning rate of the adversary model is now set to 3.9758263722433575e-05\n",
      "Epoch: [30/50] Batch: [201/268]\tClassifier_Loss: 0.5175\tAdversary Loss: 0.6078\tC(x): 0.7919\tA(x, y): 0.6269\n",
      "Learning rate of the classifier model is now set to 3.816793317353623e-05\n",
      "Learning rate of the adversary model is now set to 3.816793317353623e-05\n",
      "Epoch: [31/50] Batch: [1/268]\tClassifier_Loss: 0.5607\tAdversary Loss: 0.6082\tC(x): 0.7896\tA(x, y): 0.6267\n",
      "Learning rate of the classifier model is now set to 3.664121584659478e-05\n",
      "Learning rate of the adversary model is now set to 3.664121584659478e-05\n",
      "Learning rate of the classifier model is now set to 3.517556721273098e-05\n",
      "Learning rate of the adversary model is now set to 3.517556721273098e-05\n",
      "Epoch: [31/50] Batch: [201/268]\tClassifier_Loss: 0.4905\tAdversary Loss: 0.6286\tC(x): 0.7829\tA(x, y): 0.6261\n",
      "Learning rate of the classifier model is now set to 3.3768544524221746e-05\n",
      "Learning rate of the adversary model is now set to 3.3768544524221746e-05\n",
      "Epoch: [32/50] Batch: [1/268]\tClassifier_Loss: 0.5987\tAdversary Loss: 0.5270\tC(x): 0.7808\tA(x, y): 0.6259\n",
      "Learning rate of the classifier model is now set to 3.241780274325288e-05\n",
      "Learning rate of the adversary model is now set to 3.241780274325288e-05\n",
      "Learning rate of the classifier model is now set to 3.112109063352276e-05\n",
      "Learning rate of the adversary model is now set to 3.112109063352276e-05\n",
      "Epoch: [32/50] Batch: [201/268]\tClassifier_Loss: 0.4635\tAdversary Loss: 0.6579\tC(x): 0.7746\tA(x, y): 0.6254\n",
      "Epoch: [33/50] Batch: [1/268]\tClassifier_Loss: 0.4930\tAdversary Loss: 0.6066\tC(x): 0.7725\tA(x, y): 0.6252\n",
      "Learning rate of the classifier model is now set to 2.987624700818185e-05\n",
      "Learning rate of the adversary model is now set to 2.987624700818185e-05\n",
      "Learning rate of the classifier model is now set to 2.8681197127854573e-05\n",
      "Learning rate of the adversary model is now set to 2.8681197127854573e-05\n",
      "Epoch: [33/50] Batch: [201/268]\tClassifier_Loss: 0.4262\tAdversary Loss: 0.6201\tC(x): 0.7668\tA(x, y): 0.6247\n",
      "Learning rate of the classifier model is now set to 2.753394924274039e-05\n",
      "Learning rate of the adversary model is now set to 2.753394924274039e-05\n",
      "Epoch: [34/50] Batch: [1/268]\tClassifier_Loss: 0.5231\tAdversary Loss: 0.5660\tC(x): 0.7648\tA(x, y): 0.6245\n",
      "Learning rate of the classifier model is now set to 2.6432591273030774e-05\n",
      "Learning rate of the adversary model is now set to 2.6432591273030774e-05\n",
      "Learning rate of the classifier model is now set to 2.537528762210954e-05\n",
      "Learning rate of the adversary model is now set to 2.537528762210954e-05\n",
      "Epoch: [34/50] Batch: [201/268]\tClassifier_Loss: 0.5033\tAdversary Loss: 0.6187\tC(x): 0.7593\tA(x, y): 0.6240\n",
      "Learning rate of the classifier model is now set to 2.4360276117225157e-05\n",
      "Learning rate of the adversary model is now set to 2.4360276117225157e-05\n",
      "Epoch: [35/50] Batch: [1/268]\tClassifier_Loss: 0.6860\tAdversary Loss: 0.5707\tC(x): 0.7575\tA(x, y): 0.6239\n",
      "Learning rate of the classifier model is now set to 2.338586507253615e-05\n",
      "Learning rate of the adversary model is now set to 2.338586507253615e-05\n",
      "Learning rate of the classifier model is now set to 2.2450430469634704e-05\n",
      "Learning rate of the adversary model is now set to 2.2450430469634704e-05\n",
      "Epoch: [35/50] Batch: [201/268]\tClassifier_Loss: 0.5726\tAdversary Loss: 0.6405\tC(x): 0.7523\tA(x, y): 0.6234\n",
      "Epoch: [36/50] Batch: [1/268]\tClassifier_Loss: 0.5808\tAdversary Loss: 0.6449\tC(x): 0.7506\tA(x, y): 0.6232\n",
      "Learning rate of the classifier model is now set to 2.155241325084932e-05\n",
      "Learning rate of the adversary model is now set to 2.155241325084932e-05\n",
      "Learning rate of the classifier model is now set to 2.0690316720815342e-05\n",
      "Learning rate of the adversary model is now set to 2.0690316720815342e-05\n",
      "Epoch: [36/50] Batch: [201/268]\tClassifier_Loss: 0.5967\tAdversary Loss: 0.6562\tC(x): 0.7457\tA(x, y): 0.6227\n",
      "Learning rate of the classifier model is now set to 1.9862704051982727e-05\n",
      "Learning rate of the adversary model is now set to 1.9862704051982727e-05\n",
      "Epoch: [37/50] Batch: [1/268]\tClassifier_Loss: 0.4617\tAdversary Loss: 0.5711\tC(x): 0.7441\tA(x, y): 0.6226\n",
      "Learning rate of the classifier model is now set to 1.9068195889903417e-05\n",
      "Learning rate of the adversary model is now set to 1.9068195889903417e-05\n",
      "Learning rate of the classifier model is now set to 1.830546805430728e-05\n",
      "Learning rate of the adversary model is now set to 1.830546805430728e-05\n",
      "Epoch: [37/50] Batch: [201/268]\tClassifier_Loss: 0.5797\tAdversary Loss: 0.5500\tC(x): 0.7394\tA(x, y): 0.6222\n",
      "Learning rate of the classifier model is now set to 1.757324933213499e-05\n",
      "Learning rate of the adversary model is now set to 1.757324933213499e-05\n",
      "Epoch: [38/50] Batch: [1/268]\tClassifier_Loss: 0.6636\tAdversary Loss: 0.6144\tC(x): 0.7378\tA(x, y): 0.6220\n",
      "Learning rate of the classifier model is now set to 1.6870319358849586e-05\n",
      "Learning rate of the adversary model is now set to 1.6870319358849586e-05\n",
      "Learning rate of the classifier model is now set to 1.6195506584495604e-05\n",
      "Learning rate of the adversary model is now set to 1.6195506584495604e-05\n",
      "Epoch: [38/50] Batch: [201/268]\tClassifier_Loss: 0.5652\tAdversary Loss: 0.6055\tC(x): 0.7334\tA(x, y): 0.6217\n",
      "Epoch: [39/50] Batch: [1/268]\tClassifier_Loss: 0.6152\tAdversary Loss: 0.6044\tC(x): 0.7319\tA(x, y): 0.6215\n",
      "Learning rate of the classifier model is now set to 1.554768632111578e-05\n",
      "Learning rate of the adversary model is now set to 1.554768632111578e-05\n",
      "Learning rate of the classifier model is now set to 1.4925778868271147e-05\n",
      "Learning rate of the adversary model is now set to 1.4925778868271147e-05\n",
      "Epoch: [39/50] Batch: [201/268]\tClassifier_Loss: 0.5294\tAdversary Loss: 0.6158\tC(x): 0.7278\tA(x, y): 0.6211\n",
      "Learning rate of the classifier model is now set to 1.4328747713540301e-05\n",
      "Learning rate of the adversary model is now set to 1.4328747713540301e-05\n",
      "Epoch: [40/50] Batch: [1/268]\tClassifier_Loss: 0.5533\tAdversary Loss: 0.5540\tC(x): 0.7263\tA(x, y): 0.6210\n",
      "Learning rate of the classifier model is now set to 1.375559780499869e-05\n",
      "Learning rate of the adversary model is now set to 1.375559780499869e-05\n",
      "Learning rate of the classifier model is now set to 1.320537389279874e-05\n",
      "Learning rate of the adversary model is now set to 1.320537389279874e-05\n",
      "Epoch: [40/50] Batch: [201/268]\tClassifier_Loss: 0.4525\tAdversary Loss: 0.6347\tC(x): 0.7222\tA(x, y): 0.6206\n",
      "Learning rate of the classifier model is now set to 1.2677158937086791e-05\n",
      "Learning rate of the adversary model is now set to 1.2677158937086791e-05\n",
      "Epoch: [41/50] Batch: [1/268]\tClassifier_Loss: 0.4791\tAdversary Loss: 0.6140\tC(x): 0.7209\tA(x, y): 0.6205\n",
      "Learning rate of the classifier model is now set to 1.217007257960332e-05\n",
      "Learning rate of the adversary model is now set to 1.217007257960332e-05\n",
      "Learning rate of the classifier model is now set to 1.1683269676419186e-05\n",
      "Learning rate of the adversary model is now set to 1.1683269676419186e-05\n",
      "Epoch: [41/50] Batch: [201/268]\tClassifier_Loss: 0.5847\tAdversary Loss: 0.6529\tC(x): 0.7170\tA(x, y): 0.6201\n",
      "Epoch: [42/50] Batch: [1/268]\tClassifier_Loss: 0.5506\tAdversary Loss: 0.6337\tC(x): 0.7157\tA(x, y): 0.6200\n",
      "Learning rate of the classifier model is now set to 1.1215938889362417e-05\n",
      "Learning rate of the adversary model is now set to 1.1215938889362417e-05\n",
      "Learning rate of the classifier model is now set to 1.0767301333787921e-05\n",
      "Learning rate of the adversary model is now set to 1.0767301333787921e-05\n",
      "Epoch: [42/50] Batch: [201/268]\tClassifier_Loss: 0.5818\tAdversary Loss: 0.5735\tC(x): 0.7121\tA(x, y): 0.6197\n",
      "Learning rate of the classifier model is now set to 1.0336609280436403e-05\n",
      "Learning rate of the adversary model is now set to 1.0336609280436403e-05\n",
      "Epoch: [43/50] Batch: [1/268]\tClassifier_Loss: 0.4319\tAdversary Loss: 0.6272\tC(x): 0.7108\tA(x, y): 0.6196\n",
      "Learning rate of the classifier model is now set to 9.923144909218947e-06\n",
      "Learning rate of the adversary model is now set to 9.923144909218947e-06\n",
      "Learning rate of the classifier model is now set to 9.526219112850188e-06\n",
      "Learning rate of the adversary model is now set to 9.526219112850188e-06\n",
      "Epoch: [43/50] Batch: [201/268]\tClassifier_Loss: 0.4941\tAdversary Loss: 0.5411\tC(x): 0.7074\tA(x, y): 0.6192\n",
      "Learning rate of the classifier model is now set to 9.14517034833618e-06\n",
      "Learning rate of the adversary model is now set to 9.14517034833618e-06\n",
      "Epoch: [44/50] Batch: [1/268]\tClassifier_Loss: 0.5687\tAdversary Loss: 0.6145\tC(x): 0.7061\tA(x, y): 0.6191\n",
      "Learning rate of the classifier model is now set to 8.779363534402732e-06\n",
      "Learning rate of the adversary model is now set to 8.779363534402732e-06\n",
      "Learning rate of the classifier model is now set to 8.428188993026623e-06\n",
      "Learning rate of the adversary model is now set to 8.428188993026623e-06\n",
      "Epoch: [44/50] Batch: [201/268]\tClassifier_Loss: 0.5328\tAdversary Loss: 0.6544\tC(x): 0.7029\tA(x, y): 0.6188\n",
      "Epoch: [45/50] Batch: [1/268]\tClassifier_Loss: 0.5178\tAdversary Loss: 0.6053\tC(x): 0.7017\tA(x, y): 0.6187\n",
      "Learning rate of the classifier model is now set to 8.091061433305558e-06\n",
      "Learning rate of the adversary model is now set to 8.091061433305558e-06\n",
      "Learning rate of the classifier model is now set to 7.767418975973336e-06\n",
      "Learning rate of the adversary model is now set to 7.767418975973336e-06\n",
      "Epoch: [45/50] Batch: [201/268]\tClassifier_Loss: 0.4961\tAdversary Loss: 0.5994\tC(x): 0.6985\tA(x, y): 0.6184\n",
      "Learning rate of the classifier model is now set to 7.456722216934402e-06\n",
      "Learning rate of the adversary model is now set to 7.456722216934402e-06\n",
      "Epoch: [46/50] Batch: [1/268]\tClassifier_Loss: 0.4969\tAdversary Loss: 0.5699\tC(x): 0.6975\tA(x, y): 0.6183\n",
      "Learning rate of the classifier model is now set to 7.158453328257026e-06\n",
      "Learning rate of the adversary model is now set to 7.158453328257026e-06\n",
      "Learning rate of the classifier model is now set to 6.872115195126745e-06\n",
      "Learning rate of the adversary model is now set to 6.872115195126745e-06\n",
      "Epoch: [46/50] Batch: [201/268]\tClassifier_Loss: 0.5339\tAdversary Loss: 0.6126\tC(x): 0.6944\tA(x, y): 0.6180\n",
      "Learning rate of the classifier model is now set to 6.597230587321674e-06\n",
      "Learning rate of the adversary model is now set to 6.597230587321674e-06\n",
      "Epoch: [47/50] Batch: [1/268]\tClassifier_Loss: 0.5456\tAdversary Loss: 0.5759\tC(x): 0.6934\tA(x, y): 0.6179\n",
      "Learning rate of the classifier model is now set to 6.333341363828807e-06\n",
      "Learning rate of the adversary model is now set to 6.333341363828807e-06\n",
      "Learning rate of the classifier model is now set to 6.080007709275654e-06\n",
      "Learning rate of the adversary model is now set to 6.080007709275654e-06\n",
      "Epoch: [47/50] Batch: [201/268]\tClassifier_Loss: 0.5174\tAdversary Loss: 0.6651\tC(x): 0.6904\tA(x, y): 0.6176\n",
      "Epoch: [48/50] Batch: [1/268]\tClassifier_Loss: 0.4900\tAdversary Loss: 0.6364\tC(x): 0.6894\tA(x, y): 0.6175\n",
      "Learning rate of the classifier model is now set to 5.836807400904628e-06\n",
      "Learning rate of the adversary model is now set to 5.836807400904628e-06\n",
      "Learning rate of the classifier model is now set to 5.603335104868443e-06\n",
      "Learning rate of the adversary model is now set to 5.603335104868443e-06\n",
      "Epoch: [48/50] Batch: [201/268]\tClassifier_Loss: 0.6770\tAdversary Loss: 0.5930\tC(x): 0.6866\tA(x, y): 0.6173\n",
      "Learning rate of the classifier model is now set to 5.379201700673705e-06\n",
      "Learning rate of the adversary model is now set to 5.379201700673705e-06\n",
      "Epoch: [49/50] Batch: [1/268]\tClassifier_Loss: 0.4583\tAdversary Loss: 0.6293\tC(x): 0.6857\tA(x, y): 0.6172\n",
      "Learning rate of the classifier model is now set to 5.164033632646756e-06\n",
      "Learning rate of the adversary model is now set to 5.164033632646756e-06\n",
      "Learning rate of the classifier model is now set to 4.957472287340885e-06\n",
      "Learning rate of the adversary model is now set to 4.957472287340885e-06\n",
      "Epoch: [49/50] Batch: [201/268]\tClassifier_Loss: 0.5059\tAdversary Loss: 0.6069\tC(x): 0.6830\tA(x, y): 0.6169\n",
      "Learning rate of the classifier model is now set to 4.75917339584725e-06\n",
      "Learning rate of the adversary model is now set to 4.75917339584725e-06\n",
      "Epoch: [50/50] Batch: [1/268]\tClassifier_Loss: 0.5165\tAdversary Loss: 0.6611\tC(x): 0.6821\tA(x, y): 0.6168\n",
      "Learning rate of the classifier model is now set to 4.56880646001336e-06\n",
      "Learning rate of the adversary model is now set to 4.56880646001336e-06\n",
      "Learning rate of the classifier model is now set to 4.386054201612826e-06\n",
      "Learning rate of the adversary model is now set to 4.386054201612826e-06\n",
      "Epoch: [50/50] Batch: [201/268]\tClassifier_Loss: 0.4667\tAdversary Loss: 0.6552\tC(x): 0.6795\tA(x, y): 0.6166\n"
     ]
    }
   ],
   "source": [
    "from copy import deepcopy\n",
    "global_step, classifier_losses, adversary_losses = 0, [], []\n",
    "torch.manual_seed(seed)\n",
    "adversary_loss_weight = 0.1\n",
    "for epoch in range(num_epochs):\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        # Update learning rate(s)\n",
    "        classifier_lr_scheduler.step(global_step, classifier.__class__.__name__)\n",
    "        adversary_lr_scheduler.step(global_step, adversary.__class__.__name__)\n",
    "        # Train the classifier model\n",
    "        classifier.zero_grad()\n",
    "        batch_features = data[:][0]\n",
    "        batch_labels = data[:][1]\n",
    "        pred_labels, pred_logits = classifier(batch_features)\n",
    "        classifier_error = classifier_criterion(pred_labels, batch_labels)\n",
    "        classifier_losses.append(classifier_error.item())\n",
    "        classifier_mean_error = np.mean(classifier_losses)\n",
    "        # Adversary training\n",
    "        classifier_error.backward()#retain_graph=True)\n",
    "        # Update the parameters for the classifier layers within the adversary model\n",
    "        c_params, a_params = dict(classifier.named_parameters()), dict(adversary.named_parameters())\n",
    "        for (c_p, a_p) in zip(c_params.values(), a_params.values()):\n",
    "            a_p.data = deepcopy(c_p.data)\n",
    "        adversary.zero_grad()\n",
    "        batch_protected_attributes = data[:][2]\n",
    "        pred_protected_attributes_labels, pred_protected_attributes_logits = adversary(\n",
    "        batch_features, batch_labels)\n",
    "        adversary_error = adversary_criterion(pred_protected_attributes_labels, batch_protected_attributes)\n",
    "        adversary_error.backward()#retain_graph=True)\n",
    "        adversary_losses.append(adversary_error.item())\n",
    "        adversary_mean_error = np.mean(adversary_losses)\n",
    "        # Adjust the classifier's gradients according to the normnalized adversary gradients\n",
    "        c_params, a_params = dict(classifier.named_parameters()), dict(adversary.named_parameters())\n",
    "        for p in c_params:\n",
    "            unit_adversary_grad = normalize(a_params[p].grad)\n",
    "            c_params[p].grad -= torch.sum((c_params[p].grad * unit_adversary_grad))\n",
    "            c_params[p].grad -= adversary_loss_weight * a_params[p].grad\n",
    "        adversary_optim.step() # Update adversary model parameters\n",
    "        classifier_optim.step() # Update classifier model parameters\n",
    "        if i % 200 == 0:\n",
    "            print(\"Epoch: [%d/%d] Batch: [%d/%d]\\tClassifier_Loss: %.4f\\tAdversary Loss: %.4f\\tC(x): %.4f\\tA(x, y): %.4f\" % \\\n",
    "            (epoch + 1, num_epochs, i + 1, len(train_loader), classifier_error.item(),\n",
    "             adversary_error.item(), classifier_mean_error, adversary_mean_error))\n",
    "        global_step += 1\n",
    "    classifier.training = False\n",
    "    adversary.training = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_debiasing_train = dataset_orig_train.copy(deepcopy = True)\n",
    "dataset_debiasing_test = dataset_orig_test.copy(deepcopy = True)\n",
    "train_pred_labels = classifier(torch.from_numpy(dataset_debiasing_train.features).float())[0].cpu().detach().numpy().tolist()\n",
    "test_pred_labels = classifier(torch.from_numpy(dataset_debiasing_test.features).float())[0].cpu().detach().numpy().tolist()\n",
    "# Mutated, fairer dataset with new labels\n",
    "dataset_debiasing_train.scores = np.array(train_pred_labels, dtype=np.float64).reshape(-1, 1)\n",
    "dataset_debiasing_train.labels = (np.array(train_pred_labels)>0.5).astype(np.float64).reshape(-1,1)\n",
    "dataset_debiasing_test.scores = np.array(test_pred_labels, dtype=np.float64).reshape(-1, 1)\n",
    "dataset_debiasing_test.labels = (np.array(test_pred_labels)>0.5).astype(np.float64).reshape(-1,1)\n",
    "# Map the dataset labels to back to their original values.\n",
    "train_temp_labels = dataset_debiasing_train.labels.copy()\n",
    "train_temp_labels[(dataset_debiasing_train.labels == 1.0).ravel(), 0] = dataset_orig_train.favorable_label\n",
    "train_temp_labels[(dataset_debiasing_train.labels == 0.0).ravel(), 0] = dataset_orig_train.unfavorable_label\n",
    "dataset_debiasing_train.labels = train_temp_labels.copy()\n",
    "test_temp_labels = dataset_debiasing_test.labels.copy()\n",
    "test_temp_labels[(dataset_debiasing_test.labels == 1.0).ravel(), 0] = dataset_orig_test.favorable_label\n",
    "test_temp_labels[(dataset_debiasing_test.labels == 0.0).ravel(), 0] = dataset_orig_test.unfavorable_label\n",
    "dataset_debiasing_test.labels = test_temp_labels.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Plain model - without debiasing - dataset metrics"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: Difference in mean outcomes between unprivileged and privileged groups = -0.217658\n",
      "Test set: Difference in mean outcomes between unprivileged and privileged groups = -0.210708\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Model - with debiasing - dataset metrics"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: Difference in mean outcomes between unprivileged and privileged groups = -0.176901\n",
      "Test set: Difference in mean outcomes between unprivileged and privileged groups = -0.181430\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Plain model - without debiasing - classification metrics"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Classification accuracy = 0.805364\n",
      "Test set: Balanced classification accuracy = 0.661739\n",
      "Test set: Disparate impact = 0.000000\n",
      "Test set: Equal opportunity difference = -0.455312\n",
      "Test set: Average odds difference = -0.280433\n",
      "Test set: Theil_index = 0.176247\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Model - with debiasing - classification metrics"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Classification accuracy = 0.766669\n",
      "Test set: Balanced classification accuracy = 0.606223\n",
      "Test set: Disparate impact = 0.085242\n",
      "Test set: Equal opportunity difference = -0.304442\n",
      "Test set: Average odds difference = -0.212708\n",
      "Test set: Theil_index = 0.207168\n"
     ]
    }
   ],
   "source": [
    "# Metrics for the dataset from plain model (without debiasing)\n",
    "display(Markdown(\"#### Plain model - without debiasing - dataset metrics\"))\n",
    "print(\"Train set: Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_dataset_nodebiasing_train.mean_difference())\n",
    "print(\"Test set: Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_dataset_nodebiasing_test.mean_difference())\n",
    "\n",
    "# Metrics for the dataset from model with debiasing\n",
    "display(Markdown(\"#### Model - with debiasing - dataset metrics\"))\n",
    "metric_dataset_debiasing_train = BinaryLabelDatasetMetric(dataset_debiasing_train, \n",
    "                                             unprivileged_groups=unprivileged_groups,\n",
    "                                             privileged_groups=privileged_groups)\n",
    "\n",
    "print(\"Train set: Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_dataset_debiasing_train.mean_difference())\n",
    "\n",
    "metric_dataset_debiasing_test = BinaryLabelDatasetMetric(dataset_debiasing_test, \n",
    "                                             unprivileged_groups=unprivileged_groups,\n",
    "                                             privileged_groups=privileged_groups)\n",
    "\n",
    "print(\"Test set: Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_dataset_debiasing_test.mean_difference())\n",
    "\n",
    "\n",
    "\n",
    "display(Markdown(\"#### Plain model - without debiasing - classification metrics\"))\n",
    "print(\"Test set: Classification accuracy = %f\" % classified_metric_nodebiasing_test.accuracy())\n",
    "TPR = classified_metric_nodebiasing_test.true_positive_rate()\n",
    "TNR = classified_metric_nodebiasing_test.true_negative_rate()\n",
    "bal_acc_nodebiasing_test = 0.5*(TPR+TNR)\n",
    "print(\"Test set: Balanced classification accuracy = %f\" % bal_acc_nodebiasing_test)\n",
    "print(\"Test set: Disparate impact = %f\" % classified_metric_nodebiasing_test.disparate_impact())\n",
    "print(\"Test set: Equal opportunity difference = %f\" % classified_metric_nodebiasing_test.equal_opportunity_difference())\n",
    "print(\"Test set: Average odds difference = %f\" % classified_metric_nodebiasing_test.average_odds_difference())\n",
    "print(\"Test set: Theil_index = %f\" % classified_metric_nodebiasing_test.theil_index())\n",
    "\n",
    "\n",
    "\n",
    "display(Markdown(\"#### Model - with debiasing - classification metrics\"))\n",
    "classified_metric_debiasing_test = ClassificationMetric(dataset_orig_test, \n",
    "                                                 dataset_debiasing_test,\n",
    "                                                 unprivileged_groups=unprivileged_groups,\n",
    "                                                 privileged_groups=privileged_groups)\n",
    "print(\"Test set: Classification accuracy = %f\" % classified_metric_debiasing_test.accuracy())\n",
    "TPR = classified_metric_debiasing_test.true_positive_rate()\n",
    "TNR = classified_metric_debiasing_test.true_negative_rate()\n",
    "bal_acc_debiasing_test = 0.5*(TPR+TNR)\n",
    "print(\"Test set: Balanced classification accuracy = %f\" % bal_acc_debiasing_test)\n",
    "print(\"Test set: Disparate impact = %f\" % classified_metric_debiasing_test.disparate_impact())\n",
    "print(\"Test set: Equal opportunity difference = %f\" % classified_metric_debiasing_test.equal_opportunity_difference())\n",
    "print(\"Test set: Average odds difference = %f\" % classified_metric_debiasing_test.average_odds_difference())\n",
    "print(\"Test set: Theil_index = %f\" % classified_metric_debiasing_test.theil_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qdhvSP-nOUWz"
   },
   "source": [
    "\n",
    "    References:\n",
    "    [1] B. H. Zhang, B. Lemoine, and M. Mitchell, \"Mitigating Unwanted Biases with Adversarial Learning,\" \n",
    "    AAAI/ACM Conference on Artificial Intelligence, Ethics, and Society, 2018."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "name": "demo_adversarial_debiasing.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
